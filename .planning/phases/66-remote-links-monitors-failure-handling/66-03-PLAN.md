---
phase: 66-remote-links-monitors-failure-handling
plan: 03
type: execute
wave: 2
depends_on: ["66-01"]
files_modified:
  - crates/snow-rt/src/dist/node.rs
  - crates/snow-rt/src/actor/mod.rs
  - crates/snow-rt/src/actor/scheduler.rs
autonomous: true

must_haves:
  truths:
    - "snow_actor_link works for remote PIDs -- sends DIST_LINK to the remote node and records locally"
    - "When a local process with remote links exits, DIST_EXIT is sent to each remote node"
    - "When DIST_EXIT arrives, the local linked process receives the exit signal (crashes or gets message if trap_exit)"
    - "Remote exit propagation is bidirectional -- crash on either side propagates to the other"
    - "DIST_EXIT to a disconnected node silently drops (handle_node_disconnect handles the other side)"
  artifacts:
    - path: "crates/snow-rt/src/dist/node.rs"
      provides: "DIST_LINK, DIST_UNLINK, DIST_EXIT wire message tags and reader loop handlers, send_dist_exit helper"
      contains: "DIST_EXIT"
    - path: "crates/snow-rt/src/actor/scheduler.rs"
      provides: "handle_process_exit sends DIST_EXIT for remote linked PIDs"
      contains: "send_dist_exit"
    - path: "crates/snow-rt/src/actor/mod.rs"
      provides: "snow_actor_link extended for remote PIDs via DIST_LINK"
      contains: "DIST_LINK"
  key_links:
    - from: "crates/snow-rt/src/actor/scheduler.rs"
      to: "crates/snow-rt/src/dist/node.rs"
      via: "send_dist_exit called for remote links during handle_process_exit"
      pattern: "send_dist_exit"
    - from: "crates/snow-rt/src/dist/node.rs reader_loop_session"
      to: "crates/snow-rt/src/actor/link.rs"
      via: "DIST_EXIT handler uses propagate_exit semantics for local delivery"
      pattern: "DIST_EXIT.*encode_exit_signal|link::EXIT_SIGNAL_TAG"
---

<objective>
Add remote link exit propagation: DIST_LINK/DIST_UNLINK/DIST_EXIT wire messages, extend snow_actor_link for remote PIDs, modify handle_process_exit to send DIST_EXIT for remote links, and add reader loop handlers for incoming exit signals.

Purpose: Remote links propagate exit signals bidirectionally across nodes (FT-04). A crash on node A terminates linked processes on node B, completing the distributed fault tolerance picture.
Output: Full bidirectional remote exit propagation via wire protocol.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/66-remote-links-monitors-failure-handling/66-RESEARCH.md
@.planning/phases/66-remote-links-monitors-failure-handling/66-01-SUMMARY.md

@crates/snow-rt/src/dist/node.rs
@crates/snow-rt/src/actor/mod.rs
@crates/snow-rt/src/actor/link.rs
@crates/snow-rt/src/actor/scheduler.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add DIST_LINK/DIST_UNLINK/DIST_EXIT wire messages and extend snow_actor_link for remote PIDs</name>
  <files>crates/snow-rt/src/dist/node.rs, crates/snow-rt/src/actor/mod.rs</files>
  <action>
In `dist/node.rs`:

1. Add wire message tag constants after DIST_PEER_LIST (0x12):
   ```rust
   pub(crate) const DIST_LINK: u8 = 0x13;
   pub(crate) const DIST_UNLINK: u8 = 0x14;
   pub(crate) const DIST_EXIT: u8 = 0x15;
   ```

2. Add `send_dist_exit` public(crate) function:
   ```rust
   /// Send DIST_EXIT to propagate an exit signal to a remote linked process.
   /// Wire format: [DIST_EXIT][u64 from_pid][u64 to_pid][reason_bytes]
   /// Silently drops if session unavailable (node already disconnected).
   pub(crate) fn send_dist_exit(from_pid: ProcessId, to_pid: ProcessId, reason: &ExitReason) {
       let state = match node_state() {
           Some(s) => s,
           None => return,
       };
       let node_id = to_pid.node_id();
       let node_name = {
           let map = state.node_id_map.read();
           match map.get(&node_id) {
               Some(name) => name.clone(),
               None => return,
           }
       };
       let session = {
           let sessions = state.sessions.read();
           match sessions.get(&node_name) {
               Some(s) => Arc::clone(s),
               None => return,
           }
       };
       let mut payload = Vec::with_capacity(1 + 8 + 8 + 16);
       payload.push(DIST_EXIT);
       payload.extend_from_slice(&from_pid.as_u64().to_le_bytes());
       payload.extend_from_slice(&to_pid.as_u64().to_le_bytes());
       crate::actor::link::encode_reason(&mut payload, reason);
       let mut stream = session.stream.lock().unwrap();
       let _ = write_msg(&mut *stream, &payload);
   }
   ```

3. Add `send_dist_link` helper function:
   ```rust
   fn send_dist_link(from_pid: ProcessId, to_pid: ProcessId) {
       // Same session lookup pattern as send_dist_exit
       // Wire format: [DIST_LINK][u64 from_pid][u64 to_pid]
       // Silently drops on failure
   }
   ```

4. Add `send_dist_unlink` helper function (same pattern, DIST_UNLINK tag).

5. Add DIST_LINK, DIST_UNLINK, DIST_EXIT handlers to `reader_loop_session`:

   ```rust
   DIST_LINK => {
       // Wire format: [tag][u64 from_pid][u64 to_pid]
       if msg.len() >= 17 {
           let from_pid = ProcessId(u64::from_le_bytes(msg[1..9].try_into().unwrap()));
           let to_pid = ProcessId(u64::from_le_bytes(msg[9..17].try_into().unwrap()));
           // Add from_pid to the local process's links set
           let sched = crate::actor::global_scheduler();
           if let Some(proc_arc) = sched.get_process(to_pid) {
               proc_arc.lock().links.insert(from_pid);
           }
       }
   }
   DIST_UNLINK => {
       // Wire format: [tag][u64 from_pid][u64 to_pid]
       if msg.len() >= 17 {
           let from_pid = ProcessId(u64::from_le_bytes(msg[1..9].try_into().unwrap()));
           let to_pid = ProcessId(u64::from_le_bytes(msg[9..17].try_into().unwrap()));
           let sched = crate::actor::global_scheduler();
           if let Some(proc_arc) = sched.get_process(to_pid) {
               proc_arc.lock().links.remove(&from_pid);
           }
       }
   }
   DIST_EXIT => {
       // Wire format: [tag][u64 from_pid][u64 to_pid][reason_bytes]
       if msg.len() >= 17 {
           let from_pid = ProcessId(u64::from_le_bytes(msg[1..9].try_into().unwrap()));
           let to_pid = ProcessId(u64::from_le_bytes(msg[9..17].try_into().unwrap()));
           let reason_bytes = &msg[17..];
           if let Some((reason, _)) = crate::actor::link::decode_reason(reason_bytes) {
               let sched = crate::actor::global_scheduler();
               if let Some(proc_arc) = sched.get_process(to_pid) {
                   let mut proc = proc_arc.lock();
                   if matches!(proc.state, ProcessState::Exited(_)) {
                       continue; // Already dead, skip
                   }
                   proc.links.remove(&from_pid);
                   let is_non_crashing = matches!(reason, ExitReason::Normal | ExitReason::Shutdown);
                   if is_non_crashing || proc.trap_exit {
                       let signal_data = crate::actor::link::encode_exit_signal(from_pid, &reason);
                       let buffer = MessageBuffer::new(signal_data, crate::actor::link::EXIT_SIGNAL_TAG);
                       proc.mailbox.push(Message { buffer });
                       if matches!(proc.state, ProcessState::Waiting) {
                           proc.state = ProcessState::Ready;
                           drop(proc);
                           sched.wake_process(to_pid);
                       }
                   } else {
                       proc.state = ProcessState::Exited(ExitReason::Linked(
                           from_pid,
                           Box::new(reason),
                       ));
                   }
               }
           }
       }
   }
   ```
   Note: Import ProcessState, ExitReason, MessageBuffer, Message at the top of node.rs as needed from `crate::actor::process` and `crate::actor::heap`.

In `actor/mod.rs`:

1. Extend `snow_actor_link` to handle remote PIDs:
   - After the existing local link logic (which requires both processes in the local process table), add a remote path:
   - If `target.node_id() != 0` (remote PID):
     - Add `target` to the caller's links set (one-sided local record)
     - Send DIST_LINK wire message to the remote node via `crate::dist::node::send_dist_link(my_pid, target)`
     - The remote side's reader loop will handle DIST_LINK by adding my_pid to the remote process's links
   - Keep the existing local path unchanged for backward compatibility

2. Similarly, extend `snow_actor_unlink` (if it exists) or add `snow_actor_unlink` for remote PIDs:
   - Check if it already exists. If not, this phase doesn't need it (unlink for remote can be deferred).
   - If snow_actor_unlink exists: add remote path using send_dist_unlink.
  </action>
  <verify>Run `cargo build -p snow-rt 2>&1 | tail -20` -- no errors. Run `cargo test -p snow-rt 2>&1 | tail -10` -- all tests pass.</verify>
  <done>DIST_LINK/DIST_UNLINK/DIST_EXIT wire messages defined. snow_actor_link works for remote PIDs. send_dist_exit helper available. Reader loop handles incoming DIST_EXIT by applying exit signal to local process.</done>
</task>

<task type="auto">
  <name>Task 2: Modify handle_process_exit to send DIST_EXIT for remote links and add DIST_MONITOR_EXIT for remote monitors</name>
  <files>crates/snow-rt/src/actor/scheduler.rs</files>
  <action>
In `scheduler.rs`, modify `handle_process_exit`:

1. After extracting `linked_pids` from the exiting process, partition into local and remote:
   ```rust
   let (local_links, remote_links): (HashSet<ProcessId>, HashSet<ProcessId>) =
       linked_pids.into_iter().partition(|pid| pid.node_id() == 0);
   ```

2. Propagate to local links using existing `link::propagate_exit` (pass `local_links` instead of all `linked_pids`):
   ```rust
   let woken = link::propagate_exit(pid, &reason, local_links, |linked_pid| {
       process_table.read().get(&linked_pid).cloned()
   });
   ```

3. After local propagation, send DIST_EXIT for each remote link:
   ```rust
   for remote_pid in &remote_links {
       crate::dist::node::send_dist_exit(pid, *remote_pid, &reason);
   }
   ```
   Note: `send_dist_exit` silently drops if the node is disconnected (no panic). If the node already disconnected, `handle_node_disconnect` (from Plan 02) has already synthesized :noconnection signals locally, so there's no double-delivery.

4. Similarly for `monitored_by_entries` (added in Plan 01): partition into local and remote monitors:
   - Local monitors (monitoring_pid.node_id() == 0): deliver DOWN message directly (existing Plan 01 code)
   - Remote monitors (monitoring_pid.node_id() != 0): send DIST_MONITOR_EXIT wire message via a helper `crate::dist::node::send_dist_monitor_exit_by_pid(pid, monitoring_pid, monitor_ref, &reason)` that does the session lookup and sends the wire message. Define this as a `pub(crate)` function in `dist/node.rs`.

5. Add the `send_dist_monitor_exit_by_pid` function to `dist/node.rs`:
   ```rust
   /// Send DIST_MONITOR_EXIT to notify a remote monitoring process about a local process exit.
   pub(crate) fn send_dist_monitor_exit_by_pid(
       monitored_pid: ProcessId,
       monitoring_pid: ProcessId,
       monitor_ref: u64,
       reason: &ExitReason,
   ) {
       let state = match node_state() { Some(s) => s, None => return };
       let node_id = monitoring_pid.node_id();
       let node_name = {
           let map = state.node_id_map.read();
           match map.get(&node_id) { Some(name) => name.clone(), None => return }
       };
       let session = {
           let sessions = state.sessions.read();
           match sessions.get(&node_name) { Some(s) => Arc::clone(s), None => return }
       };
       let mut payload = Vec::with_capacity(1 + 8 + 8 + 8 + 16);
       payload.push(DIST_MONITOR_EXIT);
       payload.extend_from_slice(&monitored_pid.as_u64().to_le_bytes());
       payload.extend_from_slice(&monitoring_pid.as_u64().to_le_bytes());
       payload.extend_from_slice(&monitor_ref.to_le_bytes());
       crate::actor::link::encode_reason(&mut payload, reason);
       let mut stream = session.stream.lock().unwrap();
       let _ = write_msg(&mut *stream, &payload);
   }
   ```
  </action>
  <verify>Run `cargo build -p snow-rt 2>&1 | tail -20` -- no errors. Run `cargo test -p snow-rt 2>&1 | tail -10` -- all tests pass.</verify>
  <done>handle_process_exit partitions links into local/remote, sends DIST_EXIT for remote links, and sends DIST_MONITOR_EXIT for remote monitors. Remote exit propagation is fully bidirectional.</done>
</task>

</tasks>

<verification>
```bash
# Build succeeds
cargo build -p snow-rt 2>&1 | tail -5

# All tests pass
cargo test -p snow-rt 2>&1 | tail -10

# Verify key functions and constants
grep -n "DIST_EXIT" crates/snow-rt/src/dist/node.rs
grep -n "DIST_LINK" crates/snow-rt/src/dist/node.rs
grep -n "send_dist_exit" crates/snow-rt/src/dist/node.rs
grep -n "send_dist_exit" crates/snow-rt/src/actor/scheduler.rs
grep -n "remote_links" crates/snow-rt/src/actor/scheduler.rs
grep -n "node_id()" crates/snow-rt/src/actor/mod.rs
```
</verification>

<success_criteria>
1. DIST_LINK (0x13), DIST_UNLINK (0x14), DIST_EXIT (0x15) constants defined
2. send_dist_exit sends exit signal wire message to remote node (silently drops on failure)
3. snow_actor_link works for remote PIDs -- records locally and sends DIST_LINK
4. Reader loop handles DIST_LINK (adds to links), DIST_UNLINK (removes), DIST_EXIT (delivers exit signal)
5. DIST_EXIT handler respects trap_exit semantics
6. handle_process_exit partitions links into local/remote and sends DIST_EXIT for remote links
7. handle_process_exit sends DIST_MONITOR_EXIT for remote monitors
8. Remote exit propagation is bidirectional (crash on either side propagates)
9. All existing tests pass with zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/66-remote-links-monitors-failure-handling/66-03-SUMMARY.md`
</output>
