---
phase: 03-type-system
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/snow-common/src/token.rs
  - crates/snow-lexer/src/lib.rs
  - crates/snow-lexer/src/cursor.rs
  - crates/snow-parser/src/syntax_kind.rs
  - crates/snow-parser/src/parser/items.rs
  - crates/snow-parser/src/parser/mod.rs
  - crates/snow-parser/src/ast/item.rs
  - crates/snow-typeck/Cargo.toml
  - crates/snow-typeck/src/lib.rs
  - crates/snow-typeck/src/ty.rs
  - crates/snow-typeck/src/unify.rs
  - crates/snow-typeck/src/env.rs
  - crates/snow-typeck/src/builtins.rs
  - crates/snow-typeck/src/error.rs
  - Cargo.toml
autonomous: true

must_haves:
  truths:
    - "Lexer produces QUESTION token for ? character"
    - "Parser uses angle brackets <T> instead of square brackets [T] for generic type parameters"
    - "Parser recognizes interface, impl, and type alias declarations"
    - "Option sugar Int? and Result sugar T!E parse correctly in type positions"
    - "ena-based unification table can unify two type variables and detect occurs check violations"
  artifacts:
    - path: "crates/snow-typeck/src/ty.rs"
      provides: "Ty enum, TyVar, TyCon, Scheme types"
      contains: "enum Ty"
    - path: "crates/snow-typeck/src/unify.rs"
      provides: "Unification with occurs check"
      contains: "fn unify"
    - path: "crates/snow-typeck/src/env.rs"
      provides: "Type environment with scope stack"
      contains: "struct TypeEnv"
    - path: "crates/snow-typeck/src/builtins.rs"
      provides: "Built-in types: Int, Float, String, Bool, Option, Result"
      contains: "fn register_builtins"
    - path: "crates/snow-typeck/src/error.rs"
      provides: "TypeError with ConstraintOrigin provenance"
      contains: "enum TypeError"
  key_links:
    - from: "crates/snow-common/src/token.rs"
      to: "crates/snow-parser/src/syntax_kind.rs"
      via: "TokenKind::Question maps to SyntaxKind::QUESTION"
    - from: "crates/snow-typeck/src/ty.rs"
      to: "crates/snow-typeck/src/unify.rs"
      via: "TyVar implements ena::unify::UnifyKey"
---

<objective>
Parser migration to angle-bracket generics, new syntax support (interface, impl, type alias, Option/Result sugar), and snow-typeck crate scaffolding with core type infrastructure.

Purpose: Establishes the foundation that every subsequent type system plan builds on -- both the parser syntax changes needed for the decided type annotation syntax and the core type representation/unification machinery.

Output: Updated lexer/parser supporting Phase 3 syntax; new `snow-typeck` crate with Ty, unification, type environment, builtins, and error types.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-type-system/03-CONTEXT.md
@.planning/phases/03-type-system/03-RESEARCH.md
@crates/snow-common/src/token.rs
@crates/snow-lexer/src/lib.rs
@crates/snow-lexer/src/cursor.rs
@crates/snow-parser/src/syntax_kind.rs
@crates/snow-parser/src/parser/items.rs
@crates/snow-parser/src/parser/mod.rs
@crates/snow-parser/src/ast/item.rs
@Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Lexer and parser migration for Phase 3 syntax</name>
  <files>
    crates/snow-common/src/token.rs
    crates/snow-lexer/src/lib.rs
    crates/snow-lexer/src/cursor.rs
    crates/snow-parser/src/syntax_kind.rs
    crates/snow-parser/src/parser/items.rs
    crates/snow-parser/src/parser/mod.rs
    crates/snow-parser/src/ast/item.rs
  </files>
  <action>
    **Lexer changes:**
    1. Add `Question` variant to `TokenKind` in `crates/snow-common/src/token.rs` (between existing operators, or in a new punctuation section).
    2. Add `Interface` keyword variant to `TokenKind` (the user decided `interface` keyword for trait definitions). Note: `Impl`, `Type`, `Where`, `Trait` keywords already exist. `Interface` is NEW.
    3. In `crates/snow-lexer/src/lib.rs`, add lexing for `?` character producing `TokenKind::Question`. Check `cursor.rs` for where single-char operators are dispatched -- add `?` there. Also add "interface" to keyword dispatch (match-based, following existing pattern with `SelfKw` etc.).
    4. Update the lexer's keyword match in `lib.rs` or wherever keywords are dispatched to include `"interface" => TokenKind::Interface`.

    **SyntaxKind changes in `syntax_kind.rs`:**
    1. Add `QUESTION` to operators section (maps from `TokenKind::Question`).
    2. Add `INTERFACE_KW` to keywords section (maps from `TokenKind::Interface`).
    3. Add composite node kinds: `INTERFACE_DEF`, `INTERFACE_METHOD`, `IMPL_DEF`, `TYPE_ALIAS_DEF`, `WHERE_CLAUSE`, `TRAIT_BOUND`, `GENERIC_PARAM_LIST`, `GENERIC_ARG_LIST`.
    4. Update the `From<TokenKind>` impl for the new variants.
    5. Update tests (particularly `all_token_kinds_convert_to_syntax_kind` -- adjust the count).

    **Parser migration -- angle brackets for generics:**
    1. In `items.rs`, update `parse_type_param_list()` to use `LT`/`GT` instead of `L_BRACKET`/`R_BRACKET`. The function opens on `LT`, parses comma-separated IDENTs, closes on `GT`. Use `GENERIC_PARAM_LIST` as the node kind instead of `TYPE_PARAM_LIST`.
    2. In `items.rs`, update `parse_type()` to use `LT`/`GT` for generic arguments. After parsing the type name (IDENT with optional dot path), if `LT` follows, open a `GENERIC_ARG_LIST` node, parse comma-separated types recursively, expect `GT`. This replaces the current `L_BRACKET`/`R_BRACKET` logic.
    3. In `items.rs`, update `parse_struct_def()` to check `LT` instead of `L_BRACKET` for type params.
    4. **Disambiguation note:** In type positions (inside `parse_type()`), `<` always opens generics. No ambiguity because `parse_type()` is only called in type context. In expression context, `<` remains comparison. No changes needed to expression parser.

    **Parser -- Option/Result sugar in types:**
    1. In `parse_type()`, after parsing a type name, if `QUESTION` follows, desugar: wrap the type in an `Option` application. Concretely: open a node before the type name (using forward-parent/open_before technique), parse the `?`, close as `GENERIC_ARG_LIST` containing the original type, then the whole thing becomes an application of `Option`. Alternatively, simply produce a new node kind like `OPTION_TYPE` or reuse `GENERIC_ARG_LIST` with the `Option` constructor implicit. Simplest approach: just parse `Type?` as a `GENERIC_ARG_LIST` child of an implicit `Option` -- OR, create a dedicated AST structure. **Recommended:** Parse `Int?` and emit it as if the user wrote `Option<Int>` -- the type checker will handle the semantics. In the CST, wrap it in a `GENERIC_ARG_LIST` with the QUESTION token preserved for lossless round-trip.
    2. For `T!E` (Result sugar): After parsing a type, if `BANG` follows in type position, parse the error type after it. Emit as if `Result<T, E>`. Same structural approach.

    **Parser -- interface, impl, type alias declarations:**
    1. Add `parse_interface_def()` in `items.rs`: `interface Name do method_sigs end`. Parse `INTERFACE_KW`, NAME (IDENT), optional generic params `<T>`, `DO_KW`, method signatures (each is `fn name(params) [-> ReturnType]` without body -- parse as `INTERFACE_METHOD`), `END_KW`. Close as `INTERFACE_DEF`.
    2. Add `parse_impl_def()` in `items.rs`: `impl TraitName for TypeName do fn_defs end`. Parse `IMPL_KW`, trait path (IDENT with dots), `FOR_KW` keyword, type path, optional `WHERE_CLAUSE`, `DO_KW`, method definitions (full `parse_fn_def`), `END_KW`. Close as `IMPL_DEF`. Note: `FOR_KW` already exists in SyntaxKind.
    3. Add `parse_type_alias()` in `items.rs`: `type Name = Type`. Parse `TYPE_KW`, NAME (IDENT), optional generic params, `EQ`, `parse_type()`. Close as `TYPE_ALIAS_DEF`.
    4. Add `parse_where_clause()` in `items.rs`: `where T: TraitName, U: OtherTrait`. Parse `WHERE_KW`, then comma-separated `IDENT COLON type_path` pairs, each wrapped as `TRAIT_BOUND`. Close as `WHERE_CLAUSE`.
    5. Update `parse_item_or_stmt()` (in `parser/mod.rs` or wherever the top-level dispatch is) to recognize `INTERFACE_KW`, `IMPL_KW`, `TYPE_KW` at item level and dispatch to the new parsers.
    6. Update `parse_fn_def()` to support optional where clause before `do`: `fn name<T>(params) -> ReturnType where T: Trait do body end`.

    **AST wrappers:**
    1. In `ast/item.rs`, add typed AST wrappers for `InterfaceDef`, `ImplDef`, `TypeAliasDef` using the `ast_node!` macro. Add basic accessor methods (name, methods, type params).
    2. Update the `Item` enum to include the new declaration types.

    **Update existing snapshot tests** that will break due to angle bracket migration. Run `cargo test` and update snapshots with `cargo insta review` or `INSTA_UPDATE=always cargo test`.
  </action>
  <verify>
    `cargo test -p snow-lexer` passes (new Question token, Interface keyword).
    `cargo test -p snow-parser` passes after snapshot updates.
    Manually verify: `struct Foo<T> do x: T end` parses with GENERIC_PARAM_LIST using LT/GT.
    Manually verify: `interface Printable do fn to_string(self) -> String end` parses as INTERFACE_DEF.
    Manually verify: `impl Printable for Int do fn to_string(self) -> String do "int" end end` parses as IMPL_DEF.
    Manually verify: `type Alias = Int` parses as TYPE_ALIAS_DEF.
    Manually verify: `Int?` in type position parses as Option sugar.
  </verify>
  <done>
    Lexer produces Question token and Interface keyword. Parser uses angle brackets for generics. Interface, impl, type alias, and where clause declarations parse correctly. Option/Result sugar parses in type positions. All existing tests pass with updated snapshots.
  </done>
</task>

<task type="auto">
  <name>Task 2: snow-typeck crate with type representation, unification, environment, builtins, and errors</name>
  <files>
    Cargo.toml
    crates/snow-typeck/Cargo.toml
    crates/snow-typeck/src/lib.rs
    crates/snow-typeck/src/ty.rs
    crates/snow-typeck/src/unify.rs
    crates/snow-typeck/src/env.rs
    crates/snow-typeck/src/builtins.rs
    crates/snow-typeck/src/error.rs
  </files>
  <action>
    **Crate setup:**
    1. Add `snow-typeck` to workspace members in root `Cargo.toml`.
    2. Create `crates/snow-typeck/Cargo.toml` with dependencies: `ena = "0.14"`, `rustc-hash = "2"`, `snow-parser` (path), `snow-common` (path). Dev-dependencies: `insta` (workspace).

    **ty.rs -- Type representation:**
    1. Define `TyVar` as a newtype over `u32`. Implement `ena::unify::UnifyKey` with `type Value = Option<Ty>`. Implement `ena::unify::EqUnifyValue` for `Ty`.
    2. Define `Ty` enum with variants: `Var(TyVar)`, `Con(TyCon)`, `Fun(Vec<Ty>, Box<Ty>)`, `App(Box<Ty>, Vec<Ty>)`, `Tuple(Vec<Ty>)`, `Never`.
    3. Define `TyCon` struct with `name: String` (interned later; String for now). Implement `PartialEq`, `Eq`, `Hash`, `Clone`, `Debug`.
    4. Define `Scheme` struct: `{ vars: Vec<TyVar>, ty: Ty }` for polymorphic type schemes.
    5. Implement `Display` for `Ty` to produce human-readable type strings: `Int`, `String`, `(Int, String) -> Bool`, `Option<Int>`, `Result<String, Error>`, etc. This is used in error messages.
    6. Store a `level: u32` alongside each `TyVar` for level-based generalization. Approach: use a side-table `HashMap<TyVar, u32>` in the InferCtx (or store level in a wrapper around the ena value). Simplest: use a `Vec<u32>` indexed by `TyVar.0` for O(1) level lookup.

    **unify.rs -- Unification engine:**
    1. Define `InferCtx` struct containing: `table: InPlaceUnificationTable<TyVar>`, `current_level: u32`, `var_levels: Vec<u32>`, `errors: Vec<TypeError>`.
    2. Implement `fresh_var(&mut self) -> Ty`: creates a new type variable at `current_level`, records its level in `var_levels`.
    3. Implement `resolve(&mut self, ty: Ty) -> Ty`: follows union-find indirection. If `Ty::Var(v)`, probe the table; if it has a value, resolve recursively; otherwise return `Ty::Var(v)`.
    4. Implement `occurs_in(&mut self, var: TyVar, ty: &Ty) -> bool`: checks if `var` appears in `ty` after resolving all variables through the table. Walk the type structure recursively.
    5. Implement `unify(&mut self, a: Ty, b: Ty, origin: ConstraintOrigin) -> Result<(), TypeError>`: following the pattern from RESEARCH.md Example 1. Resolve both sides first, then match on pairs. Handle Var/Var, Var/concrete (with occurs check), Fun/Fun (arity check + pairwise), Con/Con (name equality), App/App (constructor + args), Tuple/Tuple (pairwise), Never (unifies with anything). On mismatch, return `TypeError::Mismatch`.
    6. Implement `enter_level(&mut self)` and `leave_level(&mut self)` for level-based generalization.
    7. Implement `generalize(&self, ty: Ty) -> Scheme`: collect all type variables in `ty` whose level > `current_level`, produce a `Scheme` with those as quantified vars.
    8. Implement `instantiate(&mut self, scheme: &Scheme) -> Ty`: create fresh type variables for each quantified var, substitute throughout the scheme's type.

    **env.rs -- Type environment:**
    1. Define `TypeEnv` as a scope stack: `Vec<HashMap<String, Scheme>>` (using `rustc_hash::FxHashMap` for performance).
    2. Implement `push_scope()`, `pop_scope()`, `insert(name, scheme)`, `lookup(name) -> Option<&Scheme>` (searches from top of stack down).

    **builtins.rs -- Built-in type registration:**
    1. Define a function `register_builtins(ctx: &mut InferCtx, env: &mut TypeEnv)` that:
       - Registers primitive type constructors: `Int`, `Float`, `String`, `Bool`.
       - Registers generic type constructors: `Option` (arity 1), `Result` (arity 2).
       - Registers built-in functions/operators as needed (at minimum: `+`, `-`, `*`, `/` as `(Int, Int) -> Int` and `(Float, Float) -> Float`). These will be expanded when traits are added (plan 03-04). For now, hardcode arithmetic on Int and Float.

    **error.rs -- Type error types:**
    1. Define `ConstraintOrigin` enum with variants: `FnArg { call_site: TextRange, param_idx: usize }`, `BinOp { op_span: TextRange }`, `IfBranches { if_span: TextRange, then_span: TextRange, else_span: TextRange }`, `Annotation { annotation_span: TextRange }`, `Return { return_span: TextRange, fn_span: TextRange }`, `LetBinding { binding_span: TextRange }`, `Assignment { lhs_span: TextRange, rhs_span: TextRange }`. Use `rowan::TextRange` for spans.
    2. Define `TypeError` enum with variants: `Mismatch { expected: Ty, found: Ty, origin: ConstraintOrigin }`, `InfiniteType { var: TyVar, ty: Ty, origin: ConstraintOrigin }`, `ArityMismatch { expected: usize, found: usize, origin: ConstraintOrigin }`, `UnboundVariable { name: String, span: TextRange }`, `NotAFunction { ty: Ty, span: TextRange }`.
    3. Implement `Display` for `TypeError` to produce the terse one-liner format.

    **lib.rs -- Public API stub:**
    1. Declare modules: `pub mod ty`, `pub mod unify`, `pub mod env`, `pub mod builtins`, `pub mod error`.
    2. Define a placeholder `pub fn check(parse: &snow_parser::Parse) -> TypeckResult` that returns an empty result for now (the real implementation comes in plan 03-02).
    3. Define `TypeckResult` struct: `{ types: HashMap<TextRange, Ty>, errors: Vec<TypeError> }`.

    **Tests:**
    1. In `crates/snow-typeck/src/unify.rs` (or a tests module), write unit tests:
       - Unify two fresh variables -> succeeds, both resolve to same type
       - Unify a variable with `Int` -> resolves to `Int`
       - Unify `Int` with `String` -> `TypeError::Mismatch`
       - Unify `(Int) -> String` with `(Int) -> Bool` -> mismatch on return type
       - Occurs check: unify `a` with `(a) -> Int` -> `TypeError::InfiniteType`
       - Generalize/instantiate round-trip: generalize a type with free vars, instantiate creates fresh vars
    2. Run `cargo test -p snow-typeck` -- all pass.
  </action>
  <verify>
    `cargo test -p snow-typeck` passes with all unit tests for unification, occurs check, generalization, and instantiation.
    `cargo build --workspace` succeeds (new crate integrates cleanly).
  </verify>
  <done>
    `snow-typeck` crate exists with complete type infrastructure: Ty enum with Display, ena-based unification with occurs check, level-based generalization/instantiation, type environment with scope stack, built-in type registration, and typed error representation with provenance. All unit tests pass.
  </done>
</task>

</tasks>

<verification>
1. `cargo build --workspace` compiles without errors.
2. `cargo test --workspace` passes all tests (lexer, parser with updated snapshots, typeck unit tests).
3. Parse `struct Foo<T> do x: T end` and see GENERIC_PARAM_LIST with LT/GT tokens (not L_BRACKET/R_BRACKET).
4. Parse `interface Printable do fn to_string(self) -> String end` and see INTERFACE_DEF node.
5. Parse `type Name = Int` and see TYPE_ALIAS_DEF node.
6. Unification unit test for occurs check rejects `a ~ (a) -> Int`.
7. Generalize/instantiate test produces fresh variables on each instantiation.
</verification>

<success_criteria>
- The lexer handles `?` and `interface` keyword.
- The parser uses angle brackets for generics everywhere (no more square brackets in type positions).
- Interface, impl, type alias, and where clause syntax parse into correct CST nodes.
- The `snow-typeck` crate has a complete type representation and working unification engine with occurs check, generalization, and instantiation.
- All workspace tests pass.
</success_criteria>

<output>
After completion, create `.planning/phases/03-type-system/03-01-SUMMARY.md`
</output>
