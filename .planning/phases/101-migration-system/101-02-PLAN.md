---
phase: 101-migration-system
plan: 02
type: execute
wave: 2
depends_on: ["101-01"]
files_modified:
  - crates/meshc/Cargo.toml
  - crates/meshc/src/main.rs
  - crates/meshc/src/migrate.rs
autonomous: true

must_haves:
  truths:
    - "meshc migrate up discovers pending .mpl files in migrations/, compiles each as a synthetic project, runs it, and records in _mesh_migrations tracking table"
    - "meshc migrate down finds last applied migration, compiles its down() as a synthetic project, runs it, and removes the tracking row"
    - "meshc migrate status connects to PG, reads _mesh_migrations, and prints applied vs pending migrations"
    - "Each migration runs within a transaction: synthetic main wraps up/down call in Repo.transaction for atomic DDL"
    - "meshc migrate with no migrations/ directory prints guidance message and exits 0"
    - "meshc migrate without DATABASE_URL gives clear error message"
  artifacts:
    - path: "crates/meshc/src/migrate.rs"
      provides: "Migration runner: discover, compile, run, track"
      contains: "run_migrations_up"
    - path: "crates/meshc/src/main.rs"
      provides: "Migrate CLI subcommand"
      contains: "Migrate"
    - path: "crates/meshc/Cargo.toml"
      provides: "mesh-rt and tempfile dependencies"
      contains: "mesh-rt"
  key_links:
    - from: "crates/meshc/src/main.rs"
      to: "crates/meshc/src/migrate.rs"
      via: "Commands::Migrate dispatches to migrate module functions"
      pattern: "migrate::"
    - from: "crates/meshc/src/migrate.rs"
      to: "crates/mesh-rt/src/db/pg.rs"
      via: "Direct PG connection for tracking table management"
      pattern: "mesh_pg_connect"
    - from: "crates/meshc/src/migrate.rs"
      to: "crates/meshc/src/main.rs"
      via: "Reuses build() function for compiling synthetic migration projects"
      pattern: "build"
---

<objective>
Implement the migration runner and meshc CLI integration: `meshc migrate up` applies pending migrations, `meshc migrate down` rolls back the last one, and `meshc migrate status` shows applied vs pending state.

Purpose: The runner is the orchestration layer that ties migration files to the database. It discovers .mpl files, manages the _mesh_migrations tracking table, compiles synthetic Mesh projects that call up()/down(), and executes them.

Output: New `crates/meshc/src/migrate.rs` module + Migrate CLI subcommand in main.rs.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/101-migration-system/101-RESEARCH.md
@.planning/phases/101-migration-system/101-01-SUMMARY.md

# Key source files for runner implementation:
@crates/meshc/src/main.rs
@crates/meshc/Cargo.toml
@crates/meshc/src/discovery.rs
@crates/mesh-rt/src/db/pg.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement migration runner module and CLI subcommand</name>
  <files>
    crates/meshc/Cargo.toml
    crates/meshc/src/main.rs
    crates/meshc/src/migrate.rs
  </files>
  <action>
**Step 1: Add dependencies to meshc Cargo.toml**

Add `mesh-rt = { path = "../mesh-rt" }` to `[dependencies]` in `crates/meshc/Cargo.toml`. The migration runner needs direct access to mesh-rt's PG wire protocol functions for tracking table operations. Also add `tempfile = "3"` to `[dependencies]` (currently only in dev-dependencies) for temporary directory creation during synthetic project compilation.

**Step 2: Add Migrate CLI subcommand to main.rs**

Add a `Migrate` variant to the `Commands` enum:

```rust
/// Run database migrations
Migrate {
    #[command(subcommand)]
    action: Option<MigrateAction>,

    /// Project directory (default: current directory)
    #[arg(default_value = ".")]
    dir: PathBuf,
},
```

Add the `MigrateAction` enum (derive `Subcommand`):

```rust
#[derive(Subcommand)]
enum MigrateAction {
    /// Apply all pending migrations (default)
    Up,
    /// Rollback the last applied migration
    Down,
    /// Show migration status (applied vs pending)
    Status,
    /// Generate a new migration scaffold
    Generate {
        /// Migration name (e.g., "create_users")
        name: String,
    },
}
```

Add the `Commands::Migrate` match arm in `main()`:

```rust
Commands::Migrate { action, dir } => {
    let action = action.unwrap_or(MigrateAction::Up);
    let result = match action {
        MigrateAction::Up => migrate::run_migrations_up(&dir),
        MigrateAction::Down => migrate::run_migrations_down(&dir),
        MigrateAction::Status => migrate::show_migration_status(&dir),
        MigrateAction::Generate { name } => migrate::generate_migration(&dir, &name),
    };
    if let Err(e) = result {
        eprintln!("error: {}", e);
        process::exit(1);
    }
}
```

Add `mod migrate;` at the top of main.rs.

**Step 3: Create migrate.rs module**

Create `crates/meshc/src/migrate.rs` with the following structure:

**MigrationInfo struct:**
```rust
struct MigrationInfo {
    version: i64,
    name: String,
    filename: String,
}
```

**discover_migrations(migrations_dir: &Path) -> Result<Vec<MigrationInfo>, String>**
- Read `migrations/` directory
- Filter for `.mpl` files
- Parse filename: `YYYYMMDDHHMMSS_name.mpl` -> extract version (i64) and name
- Sort by version ascending
- If no migrations/ dir exists, return empty Vec

**connect_tracking_db() -> Result<(u64, String), String>**
- Read `DATABASE_URL` from environment, return clear error if not set: `"meshc migrate: DATABASE_URL environment variable is required"`
- Call `mesh_rt::mesh_pg_connect(url_ptr)` to get a raw PG connection handle
- Return the connection handle and URL string

**ensure_tracking_table(conn: u64) -> Result<(), String>**
- Execute `CREATE TABLE IF NOT EXISTS _mesh_migrations (version BIGINT PRIMARY KEY, name TEXT NOT NULL, applied_at TIMESTAMPTZ NOT NULL DEFAULT now())` via `mesh_rt::mesh_pg_execute`
- Parse result for error

**query_applied_versions(conn: u64) -> Result<Vec<i64>, String>**
- Execute `SELECT version FROM _mesh_migrations ORDER BY version`
- Parse result rows to extract version integers
- Return sorted Vec<i64>

**run_migrations_up(project_dir: &Path) -> Result<(), String>**

The core migration up logic:
1. Connect to PG via `connect_tracking_db()`
2. Call `ensure_tracking_table(conn)`
3. Discover migrations in `project_dir.join("migrations")`
4. If no migrations dir: print `"No migrations directory found. Run 'meshc migrate generate <name>' to create your first migration."` and return Ok
5. Query applied versions
6. Filter pending (version not in applied)
7. If no pending: print `"No pending migrations"` and return Ok
8. For each pending migration:
   a. Print `"  Applying: {version}_{name}"`
   b. Create a tempfile::tempdir()
   c. Copy `migrations/{filename}` to `{tmp}/migration.mpl`
   d. Generate a synthetic `{tmp}/main.mpl` that wraps the call in `Repo.transaction`:
   ```mesh
   import Migration

   fn main() do
     let url = Env.get("DATABASE_URL")
     match Pool.open(url, 1, 2, 5000) do
       Ok(pool) ->
         let result = Repo.transaction(pool, fn(conn) ->
           Migration.up(conn)
         end)
         match result do
           Ok(_) -> IO.puts("ok")
           Err(e) ->
             IO.puts("error: " <> e)
             Process.exit(1)
         end
         Pool.close(pool)
       Err(e) ->
         IO.puts("connection error: " <> e)
         Process.exit(1)
     end
   end
   ```

   **Important:** The synthetic main uses `Repo.transaction` to wrap the migration in a transaction. The `conn` parameter inside the transaction callback is a checkout connection handle. However, Migration DSL functions take a pool handle and use `Pool.execute`. This means Migration functions should use the pool handle, not the conn handle. Adjust the synthetic main: pass `pool` directly to `Migration.up(pool)`, and wrap the whole thing in BEGIN/COMMIT manually, OR simply call `Migration.up(pool)` without transaction wrapping for now (PostgreSQL DDL is transactional within a single connection, and pool.execute does checkout/execute/checkin per call).

   **Revised synthetic main (simpler, correct):**
   ```mesh
   import Migration

   fn main() do
     let url = Env.get("DATABASE_URL")
     match Pool.open(url, 1, 2, 5000) do
       Ok(pool) ->
         match Migration.up(pool) do
           Ok(_) -> IO.puts("ok")
           Err(e) ->
             IO.puts("error: " <> e)
             Process.exit(1)
         end
         Pool.close(pool)
       Err(e) ->
         IO.puts("connection error: " <> e)
         Process.exit(1)
     end
   end
   ```

   e. Compile the temporary project using the existing `build()` function from main.rs (make `build` pub(crate) or extract it). Call `build(tmp_path, 0, false, Some(&output_path), None, &DiagnosticOptions::default())`. The output binary goes to `{tmp}/_migrate`.
   f. Execute the compiled binary via `std::process::Command::new(output_path).env("DATABASE_URL", &url).status()`
   g. Check exit code. If non-zero, return error.
   h. Record in tracking table: `INSERT INTO _mesh_migrations (version, name) VALUES ({version}, '{escaped_name}')`
   i. Print `"  Applied: {version}_{name}"`
9. Close PG connection
10. Print summary: `"Applied {N} migration(s)"`

**run_migrations_down(project_dir: &Path) -> Result<(), String>**

Rollback the last applied migration:
1. Connect + ensure tracking table
2. Query applied versions
3. If none applied: print `"No migrations to roll back"` and return Ok
4. Find the last applied version (max)
5. Find the corresponding migration file in `migrations/`
6. If file not found: error `"Migration file for version {v} not found"`
7. Create tempdir, copy file as `migration.mpl`
8. Generate synthetic main calling `Migration.down(pool)` (same pattern as up but calls `down`)
9. Compile and run
10. If successful: `DELETE FROM _mesh_migrations WHERE version = {v}`
11. Print `"  Rolled back: {version}_{name}"`
12. Close connection

**show_migration_status(project_dir: &Path) -> Result<(), String>**

Display applied vs pending:
1. Connect + ensure tracking table
2. Discover migrations
3. Query applied versions
4. Print header: `"Migration Status:"`
5. For each migration: print `"  [x] {version}_{name}"` if applied, `"  [ ] {version}_{name}"` if pending
6. Print summary: `"{applied} applied, {pending} pending"`
7. Close connection

**generate_migration stub:** For now, implement as a placeholder that returns `Err("Not yet implemented -- see plan 101-03".to_string())`. Plan 101-03 implements the full scaffold generation.

**Make build() accessible from migrate.rs:**
The `build()` function in main.rs is currently a private function. Either:
- Move it to a shared module (e.g., `compiler.rs`) and make it pub(crate), OR
- Make the existing `build()` function `pub(crate)` in main.rs

The simplest approach: make `build()` in main.rs `pub(crate)` so migrate.rs can call `crate::build(...)`.

**PG connection details:**
Use mesh-rt's PG wire protocol directly. The functions needed:
- `mesh_rt::mesh_pg_connect(url: *const MeshString) -> u64` -- connects, returns conn handle
- `mesh_rt::mesh_pg_execute(conn: u64, sql: *const MeshString) -> *mut u8` -- executes SQL, returns result
- `mesh_rt::mesh_pg_close(conn: u64)` -- closes connection

These are extern C functions. From Rust in meshc, you need to:
1. Convert Rust strings to MeshString pointers using `mesh_rt::rust_str_to_mesh()` or equivalent
2. Call the PG functions
3. Parse the result pointers

If the MeshString construction requires GC initialization, an alternative approach: use the `tokio-postgres` crate or a simple TCP connection. However, this adds a dependency. The cleanest approach: use `std::process::Command` to run a compiled Mesh helper for tracking table operations too, OR use the raw PG wire protocol directly in Rust (mesh-rt's pg.rs has the Rust implementation available as internal functions).

**Practical approach for tracking table:** Since mesh-rt's PG functions require GC (MeshString allocation), and meshc does not initialize the GC, the tracking table operations should be done differently. Two options:

Option A (recommended): Generate ANOTHER synthetic Mesh program for tracking table operations. Have a helper that generates and compiles a small Mesh program to: create the tracking table, query applied versions, insert a version, or delete a version. Run it and capture stdout for results.

Option B: Initialize mesh-rt's GC from meshc before calling PG functions. This requires calling `mesh_gc_init()`.

**Go with Option A** -- it is cleaner and doesn't couple meshc to GC internals:

- `ensure_tracking_table_via_mesh(project_dir: &Path, url: &str)` -- compile+run a tiny Mesh program that creates the tracking table
- `query_applied_via_mesh(project_dir: &Path, url: &str) -> Vec<i64>` -- compile+run a program that queries _mesh_migrations and prints versions to stdout, parse stdout
- `record_version_via_mesh(project_dir: &Path, url: &str, version: i64, name: &str)` -- compile+run a program that INSERTs the version
- `delete_version_via_mesh(project_dir: &Path, url: &str, version: i64)` -- compile+run a program that DELETEs the version

Each of these creates a small temp project with a main.mpl that uses Pool.open + Pool.execute/Pool.query + IO.puts for output. The versions are printed as one-per-line to stdout, parsed by the Rust runner.

This approach compiles 2-3 small helper programs per migration run, but compilation is fast (~100ms each based on prior benchmarks) and avoids all GC coupling issues.

**Actually, simplest overall approach:** Compile ONE synthetic Mesh program per migration command that handles everything: the "migrate up" program does tracking table creation, queries applied versions, and then applies all pending migrations in sequence. This eliminates multiple compilations but requires the Mesh program to know the list of pending migration files at compile time.

**Final recommended approach (balances simplicity and correctness):**

Generate a single synthetic Mesh program for the entire migrate up/down/status operation. The migration runner in Rust:
1. Discovers migration files (Rust -- just filesystem ops)
2. Generates a comprehensive synthetic main.mpl that:
   - Connects to DB
   - Creates tracking table if not exists
   - For `up`: queries applied versions, determines pending, imports and calls each pending migration's up() in order, records each in tracking table
   - For `down`: queries last applied, calls its down(), deletes the tracking row
   - For `status`: queries and prints status
3. Copies all needed migration .mpl files to temp dir
4. Compiles and runs

The challenge: the synthetic main needs to import multiple migration modules, and we can't use numeric-prefix module names. Solution: copy each migration file to the temp dir with a clean name (e.g., `m1.mpl`, `m2.mpl`, ...) and import as `M1`, `M2`, etc.

**Implementation plan for run_migrations_up:**

```rust
fn run_migrations_up(project_dir: &Path) -> Result<(), String> {
    let url = std::env::var("DATABASE_URL")
        .map_err(|_| "meshc migrate: DATABASE_URL environment variable is required".to_string())?;

    let migrations_dir = project_dir.join("migrations");
    if !migrations_dir.exists() {
        eprintln!("No migrations directory found. Run 'meshc migrate generate <name>' to create your first migration.");
        return Ok(());
    }

    let migrations = discover_migrations(&migrations_dir)?;
    if migrations.is_empty() {
        eprintln!("No migration files found in migrations/");
        return Ok(());
    }

    // For each migration, compile and run individually:
    // 1. First: run a "setup + query applied" helper to get applied versions
    // 2. Then: for each pending migration, compile and run it individually
    // 3. After each success: run a "record version" helper

    // Step 1: Get applied versions via a helper Mesh program
    let applied = get_applied_versions(&url)?;

    let pending: Vec<&MigrationInfo> = migrations.iter()
        .filter(|m| !applied.contains(&m.version))
        .collect();

    if pending.is_empty() {
        eprintln!("No pending migrations");
        return Ok(());
    }

    eprintln!("Running {} pending migration(s):", pending.len());

    for migration in &pending {
        eprintln!("  Applying: {}_{}", migration.version, migration.name);

        // Compile and run migration
        run_single_migration(project_dir, &url, migration, "up")?;

        // Record applied version
        record_migration(&url, migration.version, &migration.name)?;

        eprintln!("  Applied:  {}_{}", migration.version, migration.name);
    }

    eprintln!("Applied {} migration(s)", pending.len());
    Ok(())
}
```

Where `get_applied_versions`, `run_single_migration`, and `record_migration` each generate and compile a small temporary Mesh project.

For `get_applied_versions`:
```mesh
fn main() do
  let url = Env.get("DATABASE_URL")
  match Pool.open(url, 1, 2, 5000) do
    Ok(pool) ->
      Pool.execute(pool, "CREATE TABLE IF NOT EXISTS _mesh_migrations (version BIGINT PRIMARY KEY, name TEXT NOT NULL, applied_at TIMESTAMPTZ NOT NULL DEFAULT now())", [])?
      let rows = Pool.query(pool, "SELECT version FROM _mesh_migrations ORDER BY version", [])
      match rows do
        Ok(rs) ->
          # Print each version to stdout
          List.each(rs, fn(row) ->
            IO.puts(Map.get(row, "version"))
          end)
        Err(_) -> 0
      end
      Pool.close(pool)
    Err(e) ->
      IO.puts("error: " <> e)
      Process.exit(1)
  end
end
```

Parse stdout lines as i64 version numbers.

For `record_migration(url, version, name)`:
```mesh
fn main() do
  let url = Env.get("DATABASE_URL")
  match Pool.open(url, 1, 2, 5000) do
    Ok(pool) ->
      Pool.execute(pool, "INSERT INTO _mesh_migrations (version, name) VALUES ($1, $2)", ["{version}", "{name}"])?
      Pool.close(pool)
    Err(e) ->
      IO.puts("error: " <> e)
      Process.exit(1)
  end
end
```

(The version and name are inlined into the generated Mesh source as string literals.)

For `run_single_migration(project_dir, url, migration, direction)`:
- Create tempdir
- Copy migration file to `{tmp}/migration.mpl`
- Generate main.mpl that imports Migration module and calls up/down
- Compile with `crate::build(...)`
- Execute binary with DATABASE_URL set
- Check exit code

**Error handling:** If any step fails (compilation, execution, recording), stop and return the error. The user can re-run `meshc migrate up` which will skip already-applied migrations.

**Handle Process.exit:** The Mesh stdlib should have `Process.exit(code)`. Check if it exists. If not, the migration program should use a non-zero status code mechanism. Check how existing Mesh programs signal failure. If `Process.exit` is not available, the synthetic main should print "error:" prefix and the runner should check stdout for this prefix to detect failure, in addition to checking the process exit code.
  </action>
  <verify>
Run `cargo build -p meshc` -- compiles with new Migrate subcommand. Run `meshc migrate --help` -- shows Up, Down, Status, Generate subcommands. Run `meshc migrate status` with DATABASE_URL set -- connects and shows migration status. Run `meshc migrate` with no migrations/ dir -- prints guidance message.
  </verify>
  <done>
meshc migrate up/down/status subcommands work end-to-end: discovers migration files, compiles synthetic Mesh programs to execute them, manages _mesh_migrations tracking table via compiled Mesh helpers, handles missing DATABASE_URL and missing migrations/ gracefully.
  </done>
</task>

</tasks>

<verification>
1. `cargo build -p meshc` -- compiles with Migrate subcommand
2. `meshc migrate --help` -- shows usage with up/down/status/generate
3. `meshc migrate` without DATABASE_URL -- prints clear error message
4. `meshc migrate` without migrations/ dir -- prints guidance about `meshc migrate generate`
5. Full workspace builds: `cargo build --workspace`
</verification>

<success_criteria>
- `meshc migrate up` discovers, compiles, runs, and records pending migrations in timestamp order
- `meshc migrate down` rolls back the last applied migration
- `meshc migrate status` shows applied vs pending migration list
- Each migration is compiled as a synthetic Mesh project (copy to temp dir, generate main.mpl, compile, run)
- _mesh_migrations tracking table created automatically on first run
- Clear error messages for missing DATABASE_URL, missing migrations directory, failed migrations
- All existing tests pass with zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/101-migration-system/101-02-SUMMARY.md`
</output>
