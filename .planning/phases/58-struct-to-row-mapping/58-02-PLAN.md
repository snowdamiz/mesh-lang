---
phase: 58-struct-to-row-mapping
plan: 02
type: execute
wave: 2
depends_on: ["58-01"]
files_modified:
  - crates/snow-typeck/src/infer.rs
  - crates/snow-typeck/src/error.rs
  - crates/snow-typeck/src/diagnostics.rs
  - crates/snow-codegen/src/mir/lower.rs
  - crates/snow-lsp/src/analysis.rs
  - crates/snowc/tests/e2e_stdlib.rs
  - tests/e2e/deriving_row_basic.snow
  - tests/e2e/deriving_row_option.snow
  - tests/e2e/deriving_row_error.snow
autonomous: true

must_haves:
  truths:
    - "User can add deriving(Row) to a struct and call StructName.from_row(map) to get Result<T, String>"
    - "from_row correctly maps String, Int, Float, Bool fields from Map<String, String> column values"
    - "Option<T> fields receive None for NULL columns (empty string) and missing columns"
    - "Non-Option fields produce descriptive error on NULL or missing column"
    - "Pg.query_as(conn, sql, params, User.from_row) compiles and type-checks"
    - "Pool.query_as(pool, sql, params, User.from_row) compiles and type-checks"
    - "Compiler emits error when deriving(Row) on struct with non-mappable field type (List, Map, nested struct)"
  artifacts:
    - path: "crates/snow-typeck/src/infer.rs"
      provides: "Row in valid_derives, FromRow trait impl, is_row_mappable, from_row typeck resolution, Pg/Pool.query_as type signatures"
      contains: "is_row_mappable"
    - path: "crates/snow-codegen/src/mir/lower.rs"
      provides: "generate_from_row_struct MIR generation, from_row resolution in lower_field_access"
      contains: "generate_from_row_struct"
    - path: "crates/snow-typeck/src/error.rs"
      provides: "NonMappableField error variant"
      contains: "NonMappableField"
    - path: "tests/e2e/deriving_row_basic.snow"
      provides: "E2E test for basic struct-to-row mapping"
    - path: "tests/e2e/deriving_row_option.snow"
      provides: "E2E test for Option fields and NULL handling"
  key_links:
    - from: "crates/snow-typeck/src/infer.rs"
      to: "crates/snow-codegen/src/mir/lower.rs"
      via: "FromRow trait impl registration enables generate_from_row_struct in MIR lowering"
      pattern: "FromRow.*from_row"
    - from: "crates/snow-codegen/src/mir/lower.rs"
      to: "crates/snow-rt/src/db/row.rs"
      via: "Generated MIR calls snow_row_from_row_get, snow_row_parse_int/float/bool"
      pattern: "snow_row_from_row_get"
    - from: "crates/snow-typeck/src/infer.rs"
      to: "crates/snow-codegen/src/mir/lower.rs"
      via: "from_row field access resolution in typeck, from_row var lookup in MIR lower_field_access"
      pattern: "from_row"
---

<objective>
Implement the full compiler pipeline for deriving(Row): typeck validation with is_row_mappable, MIR generation for from_row, Pg/Pool.query_as type signatures, and E2E tests.

Purpose: This is the core deliverable -- after this plan, Snow programs can use `deriving(Row)` to auto-generate `from_row` functions and call `Pg.query_as` for one-step query-and-hydrate.

Output: Complete deriving(Row) support from typeck through codegen, with 3 E2E tests validating the full pipeline.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/58-struct-to-row-mapping/58-RESEARCH.md
@.planning/phases/58-struct-to-row-mapping/58-01-SUMMARY.md
@.planning/phases/49-json-serde-structs/49-02-SUMMARY.md
@crates/snow-typeck/src/infer.rs
@crates/snow-typeck/src/error.rs
@crates/snow-typeck/src/diagnostics.rs
@crates/snow-codegen/src/mir/lower.rs
@crates/snow-lsp/src/analysis.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Typeck validation and type signatures for Row, Pg.query_as, Pool.query_as</name>
  <files>
    crates/snow-typeck/src/infer.rs
    crates/snow-typeck/src/error.rs
    crates/snow-typeck/src/diagnostics.rs
    crates/snow-lsp/src/analysis.rs
  </files>
  <action>
    **Add NonMappableField error variant to `error.rs`** (after NonSerializableField, ~line 297):
    ```rust
    /// A field type in a `deriving(Row)` struct is not row-mappable.
    NonMappableField {
        struct_name: String,
        field_name: String,
        field_type: String,
    },
    ```
    Add Display impl in the same file's Display match (~line 606 area):
    ```rust
    TypeError::NonMappableField { field_name, field_type, .. } => {
        write!(f, "field `{}` has type `{}` which cannot be mapped from a database row (only Int, Float, Bool, String, and Option<T> are supported)", field_name, field_type)
    }
    ```

    **Add E0039 error code in `diagnostics.rs`** following the E0038 pattern for NonSerializableField:
    - Add a match arm for `NonMappableField` that renders the error with the struct name, field name, and field type
    - Use the same severity (Error) and label pattern as E0038

    **Add NonMappableField match arm to `snow-lsp/src/analysis.rs`** (same as NonSerializableField pattern -- return None for the span):
    ```rust
    TypeError::NonMappableField { .. } => None,
    ```

    **Add `is_row_mappable` function to `infer.rs`** (after `is_json_serializable`, ~line 2175):
    ```rust
    /// Check if a type is row-mappable for deriving(Row) validation.
    /// Row-mappable: Int, Float, Bool, String, Option<T> where T is row-mappable primitive.
    /// NOT mappable: nested structs, sum types (except Option), List, Map, Ptr.
    fn is_row_mappable(ty: &Ty) -> bool {
        match ty {
            Ty::Con(con) => matches!(con.name.as_str(), "Int" | "Float" | "Bool" | "String"),
            Ty::App(base, args) => {
                if let Ty::Con(con) = base.as_ref() {
                    if con.name == "Option" {
                        args.first().map_or(false, |t| is_row_mappable(t))
                    } else {
                        false
                    }
                } else {
                    false
                }
            }
            _ => false,
        }
    }
    ```

    **Add "Row" to `valid_derives` in `infer.rs`** -- there are TWO places (struct defs ~line 1945 and sum type defs ~line 2339). Add "Row" to both arrays. For sum types, Row should be rejected the same way as Json (or simply not registered -- Row only applies to structs). Actually, simply add "Row" to the valid_derives array so it doesn't emit "unsupported derive" -- then only register the trait impl for structs (not sum types).

    **Add Row trait registration in struct def processing** (after the Json block, ~line 2127, before `type_registry.register_struct`):
    ```rust
    // Row impl (FromRow) -- only via explicit deriving(Row), structs only
    if derive_list.iter().any(|t| t == "Row") {
        let mut row_valid = true;
        for (field_name, field_ty) in &fields {
            if !is_row_mappable(field_ty) {
                ctx.errors.push(TypeError::NonMappableField {
                    struct_name: name.clone(),
                    field_name: field_name.clone(),
                    field_type: format!("{}", field_ty),
                });
                row_valid = false;
            }
        }

        if row_valid {
            let mut from_row_methods = FxHashMap::default();
            from_row_methods.insert(
                "from_row".to_string(),
                ImplMethodSig {
                    has_self: false,
                    param_count: 1, // takes a Map<String, String>
                    return_type: Some(Ty::result(
                        Ty::Con(TyCon::new(&name)),
                        Ty::string(),
                    )),
                },
            );
            let _ = trait_registry.register_impl(TraitImplDef {
                trait_name: "FromRow".to_string(),
                impl_type: impl_ty.clone(),
                impl_type_name: name.clone(),
                methods: from_row_methods,
            });
        }
    }
    ```

    **IMPORTANT:** The `impl_ty` variable may have already been moved by the Json block. Check if `impl_ty` is consumed by the Json `register_impl` call. If so, clone it before the Json block or use `impl_ty.clone()` in the Row block. The existing Json block uses `impl_ty` (not clone) for FromJson -- so for Row, either:
    - Move the Row block BEFORE the Json block and clone `impl_ty` there
    - OR clone `impl_ty` at the start and use the clone for Row
    The safest approach: change the Json FromJson registration to use `impl_ty.clone()` (it currently consumes `impl_ty`), then the Row block can use `impl_ty.clone()` or `impl_ty` as the last consumer.

    **Add `from_row` field access resolution in typeck** (in `infer_field_access`, after the `from_json` block at ~line 4916-4935):
    ```rust
    if field_name == "from_row" {
        if let Some(_struct_info) = type_registry.lookup_struct(&base_name) {
            let struct_ty = Ty::Con(TyCon::new(&base_name));
            if trait_registry.has_impl("FromRow", &struct_ty) {
                // from_row :: Map<String, String> -> Result<StructName, String>
                let map_ty = Ty::map(Ty::string(), Ty::string());
                let result_ty = Ty::result(struct_ty, Ty::string());
                return Ok(Ty::fun(vec![map_ty], result_ty));
            }
        }
    }
    ```

    **Add Pg.query_as and Pool.query_as type signatures** in the stdlib_modules section of infer.rs where Pg and Pool module methods are defined (~line 654-742):
    - Find the Pg module section and add:
      ```
      "query_as" => Ty::fun(vec![pg_conn_ty, Ty::string(), list_string_ty, fn_ptr_ty], result_list_result_ty)
      ```
      Where `fn_ptr_ty` is a function type `Map<String, String> -> Result<T, String>` -- but since Snow uses polymorphic module functions at typeck level, use `forall a. Fun(PgConn, String, List<String>, Fun(Map<String, String>) -> Result<a, String>) -> Result<List<Result<a, String>>, String>`. Look at how `Pg.query` is typed and extend similarly.

      Actually, since Snow's typeck for module functions uses concrete signatures without full polymorphism (looking at the existing Pg.query signature pattern), use:
      - `query_as :: PgConn -> String -> List<String> -> Fun(Ptr) -> Ptr -> Result<List<Ptr>, String>`
      - The simplest approach matching existing patterns: `Pg.query_as(conn, sql, params, from_row_fn)` where from_row_fn is typed as `Fun(Map<String, String>) -> Ptr` at typeck level. Look at how the existing Pg module entries work and follow the same pattern. The function pointer is effectively opaque at typeck level since the generated `from_row` function is resolved at codegen time.

      The most pragmatic approach: type query_as with the last parameter as a generic function type. Study how the existing `Pg.transaction` is typed (it takes a callback) and follow that pattern exactly.

    - Add matching entry for Pool module.
  </action>
  <verify>
    `cargo build` compiles the full workspace.
    `cargo test -p snow-typeck` passes all existing tests.
  </verify>
  <done>
    Row is in valid_derives.
    is_row_mappable function rejects non-primitive types.
    NonMappableField error variant exists with E0039 diagnostic.
    FromRow trait impl registered for structs with deriving(Row).
    StructName.from_row type-checks correctly.
    Pg.query_as and Pool.query_as have type signatures.
  </done>
</task>

<task type="auto">
  <name>Task 2: MIR generation for from_row + E2E tests</name>
  <files>
    crates/snow-codegen/src/mir/lower.rs
    crates/snowc/tests/e2e_stdlib.rs
    tests/e2e/deriving_row_basic.snow
    tests/e2e/deriving_row_option.snow
    tests/e2e/deriving_row_error.snow
  </files>
  <action>
    **Add `generate_from_row_struct` to `lower.rs`** (after `generate_from_json_struct`, ~line 3826). This is the core of the phase. Follow `generate_from_json_struct` as the direct template but with row-specific extraction:

    ```rust
    fn generate_from_row_struct(&mut self, name: &str, fields: &[(String, MirType)]) {
        let mangled = format!("FromRow__from_row__{}", name);
        // Parameter: row :: Ptr (a Map<String, String>)
        // Returns: Ptr (a SnowResult -- Ok(struct) or Err(string))
    ```

    **MIR generation structure** (mirrors generate_from_json_struct's nested If/Let pattern):

    For each field (iterate in reverse to build inside-out):
    1. Call `snow_row_from_row_get(row, "field_name")` to get a SnowResult
       - The field name must be a string literal: use `MirExpr::StringLit("field_name".to_string())`
    2. Check `snow_result_is_ok(get_result)` using If expression
    3. If Ok: unwrap with `snow_result_unwrap(get_result)` to get the column string value
    4. Based on field type, convert the string:
       - **String**: use the column string value directly (no conversion needed)
       - **Int**: call `snow_row_parse_int(col_str)` -> check result again with is_ok/unwrap
       - **Float**: call `snow_row_parse_float(col_str)` -> check result
       - **Bool**: call `snow_row_parse_bool(col_str)` -> check result
       - **Option<String>**: check if string is empty (`snow_string_length(col_str) == 0`):
         - If empty: `alloc_option(1, 0 as Ptr)` for None
         - If non-empty: `alloc_option(0, col_str)` for Some(col_str)
         - Wrap in `alloc_result(0, option_val)` for Ok(option)
       - **Option<Int/Float/Bool>**: check if string is empty:
         - If empty: Ok(None) via `alloc_result(0, alloc_option(1, null))`
         - If non-empty: parse the inner type, then wrap in Ok(Some(val))
       - For Option fields when the GET itself fails (missing column): return Ok(None) instead of propagating the error. This is the lenient behavior from the research -- missing columns map to None for Option fields.
    5. If Err (for non-Option fields): propagate the error directly

    **For non-Option fields receiving empty string (NULL):**
    After unwrapping the column string, check `snow_string_length(col_str) == 0`:
    - If empty AND field is NOT Option: return `alloc_result(1, "column '<name>' is NULL but field is not Option")`
    - For String fields: empty string is a VALID value (not NULL), so do NOT check for empty on non-Option String fields. Only Int/Float/Bool non-Option fields should error on empty string (they can't parse "" anyway, so the parse functions will return errors -- but a descriptive NULL-specific error is better).

    **The innermost expression** (when all fields successfully extracted): build a StructLit with all field variables, wrap in `alloc_result(0, struct_ptr)`.

    **Helper function `emit_from_row_for_type`** (similar to `emit_from_json_for_type`):
    - Match on MirType to determine which parse function to call
    - For Ptr with known struct context, check if it's a known Option sum type

    **Add deriving(Row) dispatch in `lower_struct_def`** (~line 1668, after the Json block):
    ```rust
    // Row: only via explicit deriving(Row)
    if derive_list.iter().any(|t| t == "Row") {
        self.generate_from_row_struct(&name, &fields);
    }
    ```

    **Add `from_row` resolution in `lower_field_access`** (~line 5439, after the from_json block):
    ```rust
    if field == "from_row" {
        let fn_name = format!("FromRow__from_row__{}", base_name);
        if let Some(fn_ty) = self.known_functions.get(&fn_name).cloned() {
            return MirExpr::Var(fn_name, fn_ty);
        }
    }
    ```

    Note: Unlike from_json which has a `__json_decode__` wrapper (that chains json_parse + from_json), from_row does NOT need a wrapper. The `from_row` function takes the `Map<String, String>` directly, no parsing step needed.

    **Create E2E test fixtures:**

    1. **`tests/e2e/deriving_row_basic.snow`** -- basic struct with all 4 field types:
    ```snow
    struct User do
      name :: String
      age :: Int
      score :: Float
      active :: Bool
    end deriving(Row)

    fn main() do
      let row = Map.new()
        |> Map.put("name", "Alice")
        |> Map.put("age", "30")
        |> Map.put("score", "95.5")
        |> Map.put("active", "t")

      let result = User.from_row(row)
      case result do
        Ok(u) -> println("${u.name} ${u.age} ${u.score} ${u.active}")
        Err(e) -> println("Error: ${e}")
      end
    end
    ```
    Expected output: `Alice 30 95.5 true`

    2. **`tests/e2e/deriving_row_option.snow`** -- Option fields with NULL handling:
    ```snow
    struct Profile do
      name :: String
      bio :: Option<String>
      age :: Option<Int>
    end deriving(Row)

    fn main() do
      let row = Map.new()
        |> Map.put("name", "Bob")
        |> Map.put("bio", "")
        |> Map.put("age", "25")

      let result = Profile.from_row(row)
      case result do
        Ok(p) ->
          println(p.name)
          case p.bio do
            Some(b) -> println("bio: ${b}")
            None -> println("bio: none")
          end
          case p.age do
            Some(a) -> println("age: ${a}")
            None -> println("age: none")
          end
        Err(e) -> println("Error: ${e}")
      end
    end
    ```
    Expected output:
    ```
    Bob
    bio: none
    age: 25
    ```

    3. **`tests/e2e/deriving_row_error.snow`** -- missing column error for non-Option field:
    ```snow
    struct Item do
      name :: String
      count :: Int
    end deriving(Row)

    fn main() do
      let row = Map.new()
        |> Map.put("name", "Widget")

      let result = Item.from_row(row)
      case result do
        Ok(_) -> println("unexpected ok")
        Err(e) -> println(e)
      end
    end
    ```
    Expected output: `missing column: count`

    **Add E2E test entries in `crates/snowc/tests/e2e_stdlib.rs`:**
    Follow the existing pattern (see deriving_json tests) to add:
    - `test_deriving_row_basic` -- expects "Alice 30 95.5 true"
    - `test_deriving_row_option` -- expects "Bob\nbio: none\nage: 25"
    - `test_deriving_row_error` -- expects "missing column: count"
  </action>
  <verify>
    `cargo build` compiles the full workspace.
    `cargo test -p snowc -- deriving_row` passes all 3 E2E tests.
    `cargo test` passes all existing tests (no regressions).
  </verify>
  <done>
    generate_from_row_struct generates correct MIR for struct field extraction and type conversion.
    from_row resolution works in both typeck (infer_field_access) and codegen (lower_field_access).
    deriving(Row) dispatch added in lower_struct_def.
    3 E2E tests pass: basic types, Option/NULL handling, missing column error.
    Zero regressions in existing test suite.
  </done>
</task>

</tasks>

<verification>
- `cargo build` -- workspace compiles
- `cargo test -p snowc -- deriving_row` -- all 3 Row E2E tests pass
- `cargo test` -- full test suite passes, zero regressions
- Compile-fail test (manual): a struct with `tags :: List<String>` and `deriving(Row)` should produce E0039 NonMappableField error
</verification>

<success_criteria>
- `User.from_row(map)` compiles and returns `Result<User, String>` with correct field values
- Option fields receive None for empty strings (NULL) and missing columns
- Non-Option fields produce descriptive error on missing column
- `Pg.query_as(conn, sql, params, User.from_row)` type-checks correctly
- `Pool.query_as(pool, sql, params, User.from_row)` type-checks correctly
- Compiler emits E0039 error for `deriving(Row)` with non-mappable field types
- All 3 E2E tests pass
- Zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/58-struct-to-row-mapping/58-02-SUMMARY.md`
</output>
