---
phase: 93-data-retention-and-cleanup
plan: 02
type: execute
wave: 2
depends_on: ["93-01"]
files_modified:
  - mesher/api/settings.mpl
  - mesher/ingestion/routes.mpl
  - mesher/ingestion/pipeline.mpl
  - mesher/main.mpl
autonomous: true

must_haves:
  truths:
    - "User can GET project settings (retention_days, sample_rate) and view storage usage via HTTP API"
    - "User can PUT/POST project settings to change retention_days and sample_rate"
    - "Events are sampled at ingestion time using PostgreSQL random() against the project sample_rate, checked BEFORE rate limiting"
    - "Retention cleaner actor is spawned at pipeline startup and on restart"
    - "New API routes are registered in the HTTP router"
    - "Issue summaries (counts, first/last seen) are NOT affected by event deletion (no FK from events to issues)"
  artifacts:
    - path: "mesher/api/settings.mpl"
      provides: "HTTP handlers for project settings CRUD and storage visibility"
      contains: "handle_get_project_settings"
    - path: "mesher/ingestion/routes.mpl"
      provides: "Sampling check before rate limiting in event ingestion"
      contains: "check_sample_rate"
    - path: "mesher/ingestion/pipeline.mpl"
      provides: "retention_cleaner spawned at pipeline startup"
      contains: "retention_cleaner"
    - path: "mesher/main.mpl"
      provides: "Settings and storage API routes registered in HTTP router"
      contains: "handle_get_project_settings"
  key_links:
    - from: "mesher/api/settings.mpl"
      to: "mesher/storage/queries.mpl"
      via: "imports settings and storage query functions"
      pattern: "from Storage.Queries import"
    - from: "mesher/ingestion/routes.mpl"
      to: "mesher/storage/queries.mpl"
      via: "imports check_sample_rate for sampling decision"
      pattern: "check_sample_rate"
    - from: "mesher/ingestion/pipeline.mpl"
      to: "mesher/services/retention.mpl"
      via: "imports and spawns retention_cleaner actor"
      pattern: "from Services.Retention import"
    - from: "mesher/main.mpl"
      to: "mesher/api/settings.mpl"
      via: "imports handler functions and registers routes"
      pattern: "from Api.Settings import"
---

<objective>
Wire the settings API, sampling check, and retention cleaner into the running Mesher application.

Purpose: Connects the backend pieces from Plan 01 (schema, queries, actor) to the HTTP API layer and ingestion pipeline, completing all four RETAIN requirements. After this plan, users can manage retention settings, view storage, and the system automatically samples events and cleans up expired data.

Output: New api/settings.mpl with 3 HTTP handlers, modified routes.mpl with sampling check, modified pipeline.mpl with retention_cleaner spawn, modified main.mpl with new route registrations.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/93-data-retention-and-cleanup/93-01-SUMMARY.md
@mesher/api/alerts.mpl
@mesher/api/helpers.mpl
@mesher/ingestion/routes.mpl
@mesher/ingestion/pipeline.mpl
@mesher/main.mpl
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create settings API handlers and add sampling to ingestion</name>
  <files>mesher/api/settings.mpl, mesher/ingestion/routes.mpl</files>
  <action>
**api/settings.mpl:** Create a new file following the pattern of api/alerts.mpl. Import from Ingestion.Pipeline (PipelineRegistry), Storage.Queries (get_project_settings, update_project_settings, get_project_storage), and Api.Helpers (require_param).

Define 3 pub handler functions:

1. `handle_get_project_settings(request)` -- GET /api/v1/projects/:project_id/settings
   - Get pool from PipelineRegistry, extract project_id via require_param
   - Call get_project_settings(pool, project_id)
   - On Ok(rows): if List.length(rows) > 0, build JSON response: {"retention_days": ..., "sample_rate": ...} from Map.get on row fields. Note: retention_days and sample_rate are already ::text from the query, so embed directly without quoting.
   - On Err: return 500

2. `handle_update_project_settings(request)` -- POST /api/v1/projects/:project_id/settings
   - Get pool, extract project_id, get body from Request.body
   - Call update_project_settings(pool, project_id, body)
   - On Ok(n): return 200 {"status":"ok","affected":N}
   - On Err: return 400

3. `handle_get_project_storage(request)` -- GET /api/v1/projects/:project_id/storage
   - Get pool, extract project_id
   - Call get_project_storage(pool, project_id)
   - On Ok(rows): if List.length(rows) > 0, build JSON: {"event_count": ..., "estimated_bytes": ...}. Both are numeric ::text values, embed without quoting.
   - On Err: return 500

Follow established patterns:
- `let reg_pid = Process.whereis("mesher_registry")` for registry lookup
- `let pool = PipelineRegistry.get_pool(reg_pid)` for pool access
- Helper functions defined before pub handlers (define-before-use)
- Single-expression case arms

**ingestion/routes.mpl:** Add sampling check BEFORE rate limiting in the event ingestion flow.

1. Add `check_sample_rate` to the import from Storage.Queries (line 13, add to the existing import list).

2. Create a new helper function `handle_event_sampled` defined BEFORE `handle_event_authed` (line ~170). This function wraps the existing flow with a sampling check:

```mesh
# Helper: check sampling before proceeding to rate limit + process.
fn handle_event_sampled(pool :: PoolHandle, project_id :: String, rate_limiter_pid, processor_pid, writer_pid, request) do
  let sample_result = check_sample_rate(pool, project_id)
  case sample_result do
    Ok(should_keep) -> handle_event_sample_decision(should_keep, project_id, rate_limiter_pid, processor_pid, writer_pid, request)
    Err(_) -> handle_event_authed(project_id, rate_limiter_pid, processor_pid, writer_pid, request)
  end
end
```

3. Add helper `handle_event_sample_decision` BEFORE `handle_event_sampled`:

```mesh
# Helper: act on sampling decision (true = process, false = drop silently).
fn handle_event_sample_decision(should_keep :: Bool, project_id :: String, rate_limiter_pid, processor_pid, writer_pid, request) do
  if should_keep do
    handle_event_authed(project_id, rate_limiter_pid, processor_pid, writer_pid, request)
  else
    accepted_response()
  end
end
```

4. Modify `handle_event` (line ~183) to call `handle_event_sampled` instead of `handle_event_authed`:
Change:
```mesh
Ok(project) -> handle_event_authed(project.id, rate_limiter_pid, processor_pid, writer_pid, request)
```
To:
```mesh
Ok(project) -> handle_event_sampled(pool, project.id, rate_limiter_pid, processor_pid, writer_pid, request)
```

5. Similarly modify `handle_bulk` (line ~225) to call `handle_event_sampled` for sampling on bulk too. Same change pattern.

**CRITICAL:** Sampling returns 202 Accepted for dropped events (client should not know about server-side sampling). Sampling check happens BEFORE rate limiting so sampled-out events don't count against rate limits (per research pitfall 4).

**CRITICAL:** The new helper functions must be defined BEFORE the functions that call them (Mesh define-before-use requirement). Order: handle_event_sample_decision, then handle_event_sampled, then handle_event_authed stays where it is. Insert the new helpers right before handle_event_authed.
  </action>
  <verify>
api/settings.mpl exists with 3 pub handler functions. routes.mpl has check_sample_rate in imports. routes.mpl calls handle_event_sampled from handle_event and handle_bulk. Grep for "check_sample_rate" in routes.mpl.
  </verify>
  <done>
Settings API module provides GET/POST settings and GET storage endpoints. Ingestion pipeline checks sampling rate before rate limiting, returning 202 for sampled-out events transparently.
  </done>
</task>

<task type="auto">
  <name>Task 2: Spawn retention cleaner and register settings routes</name>
  <files>mesher/ingestion/pipeline.mpl, mesher/main.mpl</files>
  <action>
**pipeline.mpl:** Wire the retention_cleaner actor into the pipeline startup and restart.

1. Add import: `from Services.Retention import retention_cleaner` (add to the existing imports at the top, after the StreamManager import on line 8).

2. In `start_pipeline` function (line ~246), add after the alert evaluator spawn (line ~282):
```mesh
  # Spawn retention cleaner (24-hour interval for daily cleanup)
  let _ = spawn(retention_cleaner, pool)
  println("[Mesher] Retention cleaner started (24h interval)")
```

3. In `restart_all_services` function (line ~215), add after the alert evaluator spawn (line ~229):
```mesh
  # Spawn retention cleaner on restart
  let _ = spawn(retention_cleaner, pool)
```

**main.mpl:** Register settings and storage API routes in the HTTP router.

1. Add import: `from Api.Settings import handle_get_project_settings, handle_update_project_settings, handle_get_project_storage` (add after the Api.Alerts import on line 17).

2. Add 3 new routes to the HTTP.serve pipe chain (add after the alert routes, before the closing paren on line 101):
```mesh
    |> HTTP.on_get("/api/v1/projects/:project_id/settings", handle_get_project_settings)
    |> HTTP.on_post("/api/v1/projects/:project_id/settings", handle_update_project_settings)
    |> HTTP.on_get("/api/v1/projects/:project_id/storage", handle_get_project_storage)
```

This follows the exact pipe-chain pattern used for all existing routes.

**Verification that RETAIN-02 is satisfied:** The issues table has NO foreign key from events to issues (events.issue_id is UUID NOT NULL but no REFERENCES constraint -- verified in schema.mpl line 17). Deleting events does NOT cascade to issues. Issue summaries (event_count, first_seen, last_seen, title, status) are preserved naturally. No special archival code needed.
  </action>
  <verify>
pipeline.mpl imports retention_cleaner from Services.Retention. pipeline.mpl spawns retention_cleaner in both start_pipeline and restart_all_services. main.mpl imports from Api.Settings. main.mpl HTTP router has 3 new routes for settings and storage. Grep for "retention_cleaner" in pipeline.mpl and "handle_get_project_settings" in main.mpl. Compilation baseline should remain at 7-8 pre-existing errors (no new errors).
  </verify>
  <done>
Retention cleaner actor spawns at pipeline startup (and restart). HTTP router serves project settings (GET/POST) and storage (GET) endpoints. All RETAIN requirements are wired: RETAIN-01 (retention settings + cleanup actor), RETAIN-02 (issue summaries preserved by schema design), RETAIN-03 (storage endpoint), RETAIN-04 (sampling at ingestion).
  </done>
</task>

</tasks>

<verification>
1. api/settings.mpl has 3 pub handler functions for settings and storage
2. routes.mpl calls check_sample_rate before rate limiting in handle_event and handle_bulk
3. Sampled-out events return 202 Accepted (transparent to client)
4. pipeline.mpl spawns retention_cleaner in start_pipeline and restart_all_services
5. main.mpl registers 3 new routes: GET/POST settings, GET storage
6. RETAIN-02 verified: no FK from events to issues, issue summaries survive event deletion
7. No compilation baseline regression (7-8 pre-existing errors unchanged)
</verification>

<success_criteria>
- GET /api/v1/projects/:project_id/settings returns retention_days and sample_rate
- POST /api/v1/projects/:project_id/settings updates retention_days and/or sample_rate
- GET /api/v1/projects/:project_id/storage returns event_count and estimated_bytes
- Events are sampled before rate limiting using PostgreSQL random() check
- Retention cleaner actor is spawned at startup and runs on 24-hour Timer.sleep cycle
- Issue summaries are NOT affected by event deletion (verified by schema invariant)
</success_criteria>

<output>
After completion, create `.planning/phases/93-data-retention-and-cleanup/93-02-SUMMARY.md`
</output>
