---
phase: 68-global-registry
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/snow-rt/src/dist/global.rs
  - crates/snow-rt/src/dist/mod.rs
  - crates/snow-rt/src/dist/node.rs
  - crates/snow-rt/src/actor/mod.rs
  - crates/snow-rt/src/actor/scheduler.rs
  - crates/snow-rt/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "Global.register(name, pid) stores the name locally and broadcasts DIST_GLOBAL_REGISTER to all connected nodes"
    - "Global.whereis(name) returns the PID from the local replica without any network call"
    - "Global.unregister(name) removes the name locally and broadcasts DIST_GLOBAL_UNREGISTER to all connected nodes"
    - "When a local process exits, its global registrations are cleaned up and unregister broadcasts sent"
    - "When a node disconnects, all global registrations owned by that node are cleaned up"
  artifacts:
    - path: "crates/snow-rt/src/dist/global.rs"
      provides: "GlobalRegistry struct with register/whereis/unregister/cleanup_node/cleanup_process/snapshot/merge_snapshot"
      contains: "pub struct GlobalRegistry"
    - path: "crates/snow-rt/src/actor/mod.rs"
      provides: "snow_global_register, snow_global_whereis, snow_global_unregister extern C functions"
      contains: "snow_global_register"
    - path: "crates/snow-rt/src/dist/node.rs"
      provides: "DIST_GLOBAL_REGISTER/UNREGISTER/SYNC wire tags and reader loop handlers"
      contains: "DIST_GLOBAL_REGISTER"
  key_links:
    - from: "crates/snow-rt/src/actor/mod.rs"
      to: "crates/snow-rt/src/dist/global.rs"
      via: "snow_global_register calls global_name_registry().register() then broadcast_global_register()"
      pattern: "global_name_registry.*register"
    - from: "crates/snow-rt/src/dist/node.rs"
      to: "crates/snow-rt/src/dist/global.rs"
      via: "reader loop DIST_GLOBAL_REGISTER handler calls global_name_registry().register()"
      pattern: "DIST_GLOBAL_REGISTER.*global_name_registry"
    - from: "crates/snow-rt/src/actor/scheduler.rs"
      to: "crates/snow-rt/src/dist/global.rs"
      via: "handle_process_exit calls global_name_registry().cleanup_process()"
      pattern: "global_name_registry.*cleanup_process"
    - from: "crates/snow-rt/src/dist/node.rs"
      to: "crates/snow-rt/src/dist/global.rs"
      via: "handle_node_disconnect calls global_name_registry().cleanup_node()"
      pattern: "global_name_registry.*cleanup_node"
---

<objective>
Build the GlobalRegistry data structure, three extern "C" runtime APIs, three new wire protocol tags with reader-loop handlers, broadcast logic, and cleanup hooks for process exit and node disconnect.

Purpose: This is the runtime foundation for cluster-wide process name registration. After this plan, the global registry is fully functional at the Rust level -- processes can be registered, looked up, unregistered, and cleaned up on failure. Only the Snow compiler integration (Plan 02) and sync-on-connect (Plan 03) remain.

Output: New `global.rs` module with `GlobalRegistry`, three extern "C" functions wired through lib.rs, three wire tags with reader-loop dispatch, cleanup hooks in scheduler.rs and node.rs.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/68-global-registry/68-RESEARCH.md
@crates/snow-rt/src/actor/registry.rs (local ProcessRegistry pattern to mirror)
@crates/snow-rt/src/dist/node.rs (wire tags, reader loop, handle_node_disconnect, send_peer_list pattern)
@crates/snow-rt/src/actor/mod.rs (existing snow_actor_register/whereis pattern for extern C)
@crates/snow-rt/src/actor/scheduler.rs (handle_process_exit at line 607, local cleanup at line 671)
@crates/snow-rt/src/lib.rs (re-export pattern for extern C functions)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GlobalRegistry data structure and wire protocol constants</name>
  <files>
    crates/snow-rt/src/dist/global.rs
    crates/snow-rt/src/dist/mod.rs
    crates/snow-rt/src/dist/node.rs
  </files>
  <action>
Create `crates/snow-rt/src/dist/global.rs` with:

1. **GlobalRegistry struct** with three maps inside a SINGLE `RwLock<GlobalRegistryInner>` (single lock avoids deadlocks and inconsistency between maps):
   - `names: FxHashMap<String, (ProcessId, String)>` -- name -> (pid, owning_node_name)
   - `pid_names: FxHashMap<ProcessId, Vec<String>>` -- reverse index for process exit cleanup
   - `node_names: FxHashMap<String, Vec<String>>` -- reverse index for node disconnect cleanup

2. **Methods on GlobalRegistry:**
   - `new() -> Self`
   - `register(name: String, pid: ProcessId, node_name: String) -> Result<(), String>` -- reject if name taken
   - `whereis(name: &str) -> Option<ProcessId>` -- local lookup, no network
   - `unregister(name: &str) -> bool` -- remove from all three maps, return true if found
   - `cleanup_node(node_name: &str) -> Vec<String>` -- remove all names for a node, return removed names
   - `cleanup_process(pid: ProcessId) -> Vec<String>` -- remove all names for a PID, return removed names
   - `snapshot() -> Vec<(String, ProcessId, String)>` -- for sync on connect (Plan 03)
   - `merge_snapshot(entries: Vec<(String, ProcessId, String)>)` -- idempotent merge for sync

3. **Static singleton:** `static GLOBAL_NAME_REGISTRY: OnceLock<GlobalRegistry>` with `pub fn global_name_registry() -> &'static GlobalRegistry`.

4. **Broadcast functions** (pub(crate)):
   - `broadcast_global_register(name: &str, pid: ProcessId, node_name: &str)` -- build DIST_GLOBAL_REGISTER payload, iterate sessions, write to each. Drop sessions lock before writing (follow send_peer_list pattern).
   - `broadcast_global_unregister(name: &str)` -- build DIST_GLOBAL_UNREGISTER payload, same broadcast pattern.

5. **Wire format constants** in `dist/node.rs`:
   - `pub(crate) const DIST_GLOBAL_REGISTER: u8 = 0x1B;`
   - `pub(crate) const DIST_GLOBAL_UNREGISTER: u8 = 0x1C;`
   - `pub(crate) const DIST_GLOBAL_SYNC: u8 = 0x1D;`

6. **Reader loop handlers** in `dist/node.rs` `reader_loop_session` match:
   - `DIST_GLOBAL_REGISTER` -- parse name, pid, node_name; call `global_name_registry().register()`, silently drop errors
   - `DIST_GLOBAL_UNREGISTER` -- parse name; call `global_name_registry().unregister()`
   - `DIST_GLOBAL_SYNC` -- parse count + entries; call `global_name_registry().merge_snapshot()`

7. **Module declaration** in `dist/mod.rs`: add `pub mod global;`

Wire formats (all little-endian):
- DIST_GLOBAL_REGISTER: `[tag 0x1B][u16 name_len][name bytes][u64 pid][u16 node_name_len][node_name bytes]`
- DIST_GLOBAL_UNREGISTER: `[tag 0x1C][u16 name_len][name bytes]`
- DIST_GLOBAL_SYNC: `[tag 0x1D][u32 count][(u16 name_len, name, u64 pid, u16 node_len, node_name)*]`

**PID handling in wire messages:** When broadcasting a register for a local PID (node_id=0), reconstruct the PID with the node's own node_id before putting it on the wire. The owning node name is already in the message, so on the receiving side the PID will correctly reference the remote node. Use the approach: for each session, reconstruct the PID using `ProcessId::from_remote(session.node_id, session.creation, pid.local_id())` -- but since different sessions assign different node_ids to the same remote node, instead embed the raw local_id in the wire message and let the receiver reconstruct using its local session info. Actually, the simpler approach: just send the PID as-is (u64). The owning_node_name field tells receivers who owns the PID. When a receiver needs to send to this PID, it will look up the node by name and route accordingly. Since we already have node_name -> session mapping, this works. The PID stored in the global registry on remote nodes will have node_id=0 (the originator's local form), but that's fine because the registry also stores the owning node_name. When the user calls `send(pid, msg)`, the PID's node_id=0 means "local to the originator" which won't route correctly. So: the sender must reconstruct the PID with the correct node_id for its own session. **Better approach:** Include the originator's node_name. On the receiving side, when inserting into the global registry, reconstruct the PID using the session's node_id and creation. The reader loop has access to the session (it knows which session the message came from). So in the DIST_GLOBAL_REGISTER handler, replace the raw PID's node_id with the session's node_id and creation if the PID has node_id=0 (meaning it was local to the sender). Use `ProcessId::from_remote(session.node_id, session.creation, pid_local_id)`. For PIDs that already have a non-zero node_id (registered on behalf of another node), keep as-is.

**Important broadcast pattern:** Follow `send_peer_list` exactly: read sessions into a Vec of Arc<NodeSession>, drop the sessions lock, THEN iterate and write. Never hold sessions lock while writing to stream.
  </action>
  <verify>
`cargo build -p snow-rt` compiles. The new global.rs module is syntactically correct. All existing tests pass: `cargo test -p snow-rt`.
  </verify>
  <done>
GlobalRegistry with all 8 methods exists in global.rs. Three wire constants defined. Three reader loop handlers dispatching to GlobalRegistry methods. Broadcast functions follow the established send_peer_list pattern. Module re-exported from dist/mod.rs. All snow-rt tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add extern "C" runtime APIs and cleanup hooks</name>
  <files>
    crates/snow-rt/src/actor/mod.rs
    crates/snow-rt/src/actor/scheduler.rs
    crates/snow-rt/src/lib.rs
  </files>
  <action>
1. **Three extern "C" functions** in `actor/mod.rs`:

   - `snow_global_register(name_ptr: *const u8, name_len: u64, pid: u64) -> u64`:
     - Extract name string from ptr+len (with UTF-8 validation, return 1 on invalid)
     - Create ProcessId from pid u64
     - Determine owning node_name: if node is started, use `node_state().name`; else use `"nonode@nohost"`
     - Call `global_name_registry().register(name, pid, node_name)`
     - On success: call `broadcast_global_register(&name, pid, &node_name)`, return 0
     - On error: return 1

   - `snow_global_whereis(name_ptr: *const u8, name_len: u64) -> u64`:
     - Extract name string from ptr+len
     - Call `global_name_registry().whereis(name)`
     - Return `pid.as_u64()` if found, 0 if not

   - `snow_global_unregister(name_ptr: *const u8, name_len: u64) -> u64`:
     - Extract name string from ptr+len
     - Call `global_name_registry().unregister(&name)`
     - On success: call `broadcast_global_unregister(&name)`, return 0
     - On failure: return 1

   Follow the exact pattern of existing `snow_actor_register` (line ~755) and `snow_actor_whereis` (line ~787) for the unsafe string extraction.

2. **Global registry cleanup in `handle_process_exit`** in `scheduler.rs`:
   After the existing local registry cleanup at line 671 (`registry::global_registry().cleanup_process(pid)`), add:
   ```rust
   // Phase 68: Clean up global registrations for the exiting process.
   let removed_global_names = crate::dist::global::global_name_registry().cleanup_process(pid);
   if !removed_global_names.is_empty() {
       for name in &removed_global_names {
           crate::dist::global::broadcast_global_unregister(name);
       }
   }
   ```

3. **Global registry cleanup in `handle_node_disconnect`** in `dist/node.rs`:
   After the existing link/monitor cleanup (at the end of handle_node_disconnect), add:
   ```rust
   // Phase 68: Clean up global registrations for the disconnected node.
   let removed_names = crate::dist::global::global_name_registry().cleanup_node(node_name);
   for name in &removed_names {
       crate::dist::global::broadcast_global_unregister(&name);
   }
   ```

4. **Re-exports** in `lib.rs`: Add `snow_global_register`, `snow_global_whereis`, `snow_global_unregister` to the `pub use` block.
  </action>
  <verify>
`cargo build -p snow-rt` compiles. All existing tests pass: `cargo test -p snow-rt`. The three new extern "C" functions are visible in lib.rs exports.
  </verify>
  <done>
Three extern "C" functions (snow_global_register, snow_global_whereis, snow_global_unregister) are callable from LLVM-generated code. Cleanup hooks fire on both process exit and node disconnect, broadcasting unregister messages to remaining nodes. All snow-rt tests pass with no regressions.
  </done>
</task>

</tasks>

<verification>
1. `cargo build -p snow-rt` compiles without errors
2. `cargo test -p snow-rt` -- all existing tests pass (no regressions)
3. `global.rs` exists with GlobalRegistry struct and all 8 methods
4. Three wire constants (0x1B, 0x1C, 0x1D) defined in node.rs
5. Reader loop handles all three new message types
6. Three extern "C" functions exist in actor/mod.rs and are re-exported from lib.rs
7. handle_process_exit includes global registry cleanup
8. handle_node_disconnect includes global registry cleanup
</verification>

<success_criteria>
The global registry runtime is fully operational: register/whereis/unregister work locally, mutations broadcast to all connected nodes via wire protocol, incoming broadcasts update the local replica, process exit and node disconnect both clean up stale registrations. Zero regressions in existing test suite.
</success_criteria>

<output>
After completion, create `.planning/phases/68-global-registry/68-01-SUMMARY.md`
</output>
