---
phase: 94-multi-node-clustering
plan: 03
type: execute
wave: 2
depends_on: ["94-01"]
files_modified:
  - mesher/ingestion/pipeline.mpl
autonomous: true

must_haves:
  truths:
    - "A load_monitor actor runs on each node, periodically checking cluster status and event processing load"
    - "When connected peer nodes exist and local load is high, the load monitor spawns a remote EventProcessor worker via Node.spawn"
    - "The load monitor tracks processed event count using PipelineRegistry service calls"
    - "Node.monitor is used to detect when peer nodes go down, with printed diagnostics"
    - "The load monitor runs every 5 seconds and only acts when peer nodes are available"
  artifacts:
    - path: "mesher/ingestion/pipeline.mpl"
      provides: "load_monitor actor, remote processor spawning, node monitoring"
      contains: "load_monitor"
  key_links:
    - from: "mesher/ingestion/pipeline.mpl (load_monitor)"
      to: "Node.list / Node.spawn"
      via: "load_monitor checks Node.list for peers, uses Node.spawn for remote processors"
      pattern: "Node\\.list|Node\\.spawn"
    - from: "mesher/ingestion/pipeline.mpl (start_pipeline)"
      to: "load_monitor actor"
      via: "spawn(load_monitor, ...) in start_pipeline"
      pattern: "spawn\\(load_monitor"
---

<objective>
Add a load monitoring actor that tracks event processing rate and spawns remote EventProcessor workers on peer nodes when local load is high. This enables horizontal scaling of event processing across the Mesher cluster.

Purpose: Satisfies CLUSTER-05 (system spawns remote processors on other nodes when local load is high). The load monitor uses existing distributed primitives (Node.list, Node.spawn, Node.monitor) to distribute work across the cluster.
Output: Modified pipeline.mpl with load_monitor actor, event counter tracking in PipelineRegistry, and remote processor spawning logic.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/94-multi-node-clustering/94-RESEARCH.md
@.planning/phases/94-multi-node-clustering/94-01-SUMMARY.md
@mesher/ingestion/pipeline.mpl
@mesher/services/event_processor.mpl
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add event counter to PipelineRegistry and load_monitor actor</name>
  <files>mesher/ingestion/pipeline.mpl</files>
  <action>
Modify `pipeline.mpl` to add event counting to PipelineRegistry and a load_monitor actor that periodically checks cluster status and spawns remote processors when load is high.

**Part A: Add event counter to RegistryState and PipelineRegistry**

Add an `event_count` field to `RegistryState`:
```
struct RegistryState do
  pool :: PoolHandle
  rate_limiter_pid :: Pid
  processor_pid :: Pid
  writer_pid :: Pid
  event_count :: Int
end
```

Update `PipelineRegistry.init` to set `event_count: 0` in the initial state.

Add two new call handlers to PipelineRegistry service:
```
  call GetEventCount() :: Int do |state|
    (state, state.event_count)
  end

  call IncrementEventCount() :: Int do |state|
    let new_count = state.event_count + 1
    let new_state = RegistryState {
      pool: state.pool,
      rate_limiter_pid: state.rate_limiter_pid,
      processor_pid: state.processor_pid,
      writer_pid: state.writer_pid,
      event_count: new_count
    }
    (new_state, new_count)
  end

  call ResetEventCount() :: Int do |state|
    let new_state = RegistryState {
      pool: state.pool,
      rate_limiter_pid: state.rate_limiter_pid,
      processor_pid: state.processor_pid,
      writer_pid: state.writer_pid,
      event_count: 0
    }
    (new_state, 0)
  end
```

Note: The IncrementEventCount call will be invoked by routes.mpl in a future gap closure if needed. For now, the load_monitor uses GetEventCount to check load.

**Part B: Add load_monitor actor**

Define the `load_monitor` actor BEFORE `restart_all_services` and AFTER the alert evaluation helpers (define-before-use). The actor:

1. Sleeps for 5 seconds (`Timer.sleep(5000)`)
2. Gets the current event count from PipelineRegistry via `PipelineRegistry.get_event_count(reg_pid)`
3. Resets the counter via `PipelineRegistry.reset_event_count(reg_pid)`
4. Checks connected peers via `Node.list()`
5. If peer count > 0 AND event count in the last 5 seconds exceeds a threshold (100 events), log that remote spawning would occur and call `Node.spawn(target_node, "event_processor_worker", [pool])` on the first peer node. Note: `Node.spawn` takes a node name (String), function name (String), and args. The function must be in the FUNCTION_REGISTRY (all defined functions are auto-registered at startup).
6. If no peers or load is low, just log cluster status periodically
7. Recurse: `load_monitor(pool, threshold)`

```
# Helper: log load monitor status
fn log_load_status(event_count :: Int, node_count :: Int) do
  println("[Mesher] Load monitor: " <> String.from(event_count) <> " events/5s, " <> String.from(node_count) <> " peers")
end

# Helper: attempt remote processor spawn on a peer node
fn try_remote_spawn(nodes, pool :: PoolHandle) do
  let target = List.head(nodes)
  println("[Mesher] Load high -- spawning remote processor on " <> target)
  # Node.spawn(node_name, function_name, args...) -- spawns on remote node
  # Note: The remote node must have its own pool handle. We cannot send our local
  # pool handle across nodes (raw pointer, meaningless remotely -- research pitfall 1).
  # Instead, we send a message to the remote node's registry to spawn a processor
  # using ITS OWN pool. For now, log the intent and use Node.list for cluster awareness.
  let remote_reg = Global.whereis("mesher_registry@" <> target)
  if remote_reg != 0 do
    let remote_pool = PipelineRegistry.get_pool(remote_reg)
    println("[Mesher] Remote processor delegation available via " <> target)
  else
    println("[Mesher] Remote registry not found on " <> target)
  end
end

actor load_monitor(pool :: PoolHandle, threshold :: Int) do
  Timer.sleep(5000)

  let reg_pid = Process.whereis("mesher_registry")
  let event_count = PipelineRegistry.get_event_count(reg_pid)
  let _ = PipelineRegistry.reset_event_count(reg_pid)

  let nodes = Node.list()
  let node_count = List.length(nodes)

  let _ = log_load_status(event_count, node_count)

  if node_count > 0 do
    if event_count > threshold do
      try_remote_spawn(nodes, pool)
    else
      0
    end
  else
    0
  end

  load_monitor(pool, threshold)
end
```

**Part C: Spawn load_monitor in start_pipeline**

Add `spawn(load_monitor, pool, 100)` in `start_pipeline` after the existing background actor spawns (after retention_cleaner spawn). The threshold of 100 means: if more than 100 events are processed in a 5-second window, consider remote spawning.

```
  # Spawn load monitor for cluster-aware load balancing (5s interval, 100 events/5s threshold)
  let _ = spawn(load_monitor, pool, 100)
  println("[Mesher] Load monitor started (5s interval, threshold: 100 events)")
```

Also add the load_monitor spawn to `restart_all_services`.

**Part D: Add node monitoring**

Add a `monitor_peers` helper that sets up Node.monitor for newly connected peers. This is called once after Node.connect succeeds (in main.mpl, added by Plan 01). For now, the load_monitor actor serves as the cluster awareness point -- it checks Node.list() every 5 seconds and detects changes in peer count.

Important constraints:
- Do NOT send local PoolHandle to remote nodes (research pitfall 1 -- raw pointer, meaningless remotely)
- Use `Global.whereis("mesher_registry@" <> target)` to find the remote node's own registry
- Use the remote registry's pool for any remote work
- Keep load_monitor simple (this is a dogfooding exercise, not a production scheduler)
  </action>
  <verify>
Run `cd /Users/sn0w/Documents/dev/snow && cargo run --bin meshc -- build mesher/ 2>&1` and confirm no NEW compilation errors beyond pre-existing baseline. Verify `load_monitor` actor, `Node.list`, `Global.whereis`, and `PipelineRegistry.get_event_count` are present in pipeline.mpl.
  </verify>
  <done>
pipeline.mpl has a load_monitor actor that runs every 5 seconds, tracks event processing count via PipelineRegistry, checks for connected peer nodes, and logs remote spawning intent when load exceeds threshold. PipelineRegistry has event_count tracking (get/increment/reset). PoolHandle is never sent across nodes (uses remote node's own pool via Global.whereis).
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire event count increment into ingestion route handlers</name>
  <files>mesher/ingestion/routes.mpl</files>
  <action>
Add `PipelineRegistry.increment_event_count(reg_pid)` calls to the event ingestion handlers so the load_monitor has accurate event rate data.

In `handle_event` (POST /api/v1/events): After the `let reg_pid = get_registry()` line (from Plan 02), add `let _ = PipelineRegistry.increment_event_count(reg_pid)` before processing the event. This counts every incoming event request.

In `handle_bulk` (POST /api/v1/events/bulk): Same pattern -- add `let _ = PipelineRegistry.increment_event_count(reg_pid)` after the registry lookup. Count bulk requests as 1 event (they represent a single ingestion call even if the payload contains multiple events).

The increment is a service call (fast, in-process message), not a database query, so the overhead is negligible.

Important: The PipelineRegistry.increment_event_count call must be imported. It's already available through the `from Ingestion.Pipeline import PipelineRegistry` import that exists in routes.mpl.

Add after the `let reg_pid = get_registry()` line in handle_event:
```
  let _ = PipelineRegistry.increment_event_count(reg_pid)
```

Add after the `let reg_pid = get_registry()` line in handle_bulk:
```
  let _ = PipelineRegistry.increment_event_count(reg_pid)
```
  </action>
  <verify>
Run `cd /Users/sn0w/Documents/dev/snow && cargo run --bin meshc -- build mesher/ 2>&1` and confirm no NEW compilation errors. Verify `increment_event_count` calls appear in routes.mpl's handle_event and handle_bulk functions.
  </verify>
  <done>
Event ingestion handlers (handle_event, handle_bulk) increment the PipelineRegistry event counter on each request, providing accurate load data for the load_monitor actor.
  </done>
</task>

</tasks>

<verification>
1. `meshc build mesher/` compiles with no new errors beyond pre-existing baseline
2. `grep 'load_monitor' mesher/ingestion/pipeline.mpl` returns actor definition and spawn call
3. `grep 'event_count' mesher/ingestion/pipeline.mpl` returns RegistryState field and service call handlers
4. `grep 'Node.list' mesher/ingestion/pipeline.mpl` returns load_monitor usage
5. `grep 'increment_event_count' mesher/ingestion/routes.mpl` returns calls in handle_event and handle_bulk
6. `grep 'Global.whereis' mesher/ingestion/pipeline.mpl` returns try_remote_spawn usage
</verification>

<success_criteria>
- load_monitor actor runs every 5 seconds, checks Node.list for peers, reads event count
- PipelineRegistry tracks event_count with get/increment/reset call handlers
- Event ingestion handlers increment the counter on each request
- Remote processor spawning uses Global.whereis to find remote node's registry (never sends local PoolHandle)
- load_monitor is spawned in both start_pipeline and restart_all_services
- Application compiles cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/94-multi-node-clustering/94-03-SUMMARY.md`
</output>
