---
phase: 94-multi-node-clustering
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mesher/main.mpl
  - mesher/ingestion/pipeline.mpl
autonomous: true

must_haves:
  truths:
    - "Mesher node starts with a unique name and cookie read from environment variables"
    - "Mesher node connects to a seed peer if MESHER_PEERS is set, forming a mesh via auto-gossip"
    - "Mesher node runs in standalone mode (no distribution) when env vars are absent"
    - "PipelineRegistry is registered globally via Global.register for cross-node discovery"
    - "Node startup happens after PG connection but before HTTP/WS servers start"
  artifacts:
    - path: "mesher/main.mpl"
      provides: "Node startup with env-based configuration"
      contains: "Node.start"
    - path: "mesher/ingestion/pipeline.mpl"
      provides: "Global service registration after pipeline startup"
      contains: "Global.register"
  key_links:
    - from: "mesher/main.mpl"
      to: "mesher/ingestion/pipeline.mpl"
      via: "start_node called before start_pipeline, both called from start_services"
      pattern: "start_node.*Node\\.start"
    - from: "mesher/ingestion/pipeline.mpl"
      to: "Global.register"
      via: "register_global_services called at end of start_pipeline"
      pattern: "Global\\.register"
---

<objective>
Add distributed node startup and global service registration to Mesher so that multiple Mesher nodes can form a cluster and discover each other's services.

Purpose: Satisfies CLUSTER-01 (mesh formation via Node.connect) and CLUSTER-02 (global process registry for cross-node service discovery). This is the foundation that Plans 02 and 03 build upon.
Output: Modified main.mpl with env-based node configuration; modified pipeline.mpl with Global.register calls for PipelineRegistry.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/94-multi-node-clustering/94-RESEARCH.md
@mesher/main.mpl
@mesher/ingestion/pipeline.mpl
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add node startup with env-based configuration to main.mpl</name>
  <files>mesher/main.mpl</files>
  <action>
Add a `start_node()` function to `main.mpl` that reads node configuration from environment variables and starts the distributed node. This function must be called AFTER the PG pool is opened but BEFORE `start_services(pool)`.

The function should:

1. Read `MESHER_NODE_NAME` via `Env.get("MESHER_NODE_NAME")`. `Env.get` returns `Option<String>`. Use case/pattern match: `Some(name) -> ...`, `None -> ...`.

2. Read `MESHER_COOKIE` via `Env.get("MESHER_COOKIE")`. Default behavior if not set: skip node startup entirely (standalone mode).

3. If both name and cookie are present, call `Node.start(node_name, cookie)` which returns Int (0 on success). Print startup confirmation.

4. Read `MESHER_PEERS` via `Env.get("MESHER_PEERS")`. If set and non-empty, call `Node.connect(peer)` for the peer address. Node.connect returns Int (0 on success). Print connection result. Note: for simplicity, support a single seed peer -- mesh auto-gossip (Phase 65) will discover additional peers automatically.

5. If env vars are absent, print "[Mesher] Running in standalone mode (no distribution)" and continue normally. The application must work identically to the current single-node behavior when no env vars are set.

Important constraints:
- `Env.get` returns `Option<String>`, so use `case` with `Some(val)` / `None` arms
- Define `start_node()` BEFORE `start_services(pool)` in the file (Mesh define-before-use requirement)
- Node name format: e.g., "mesher1@localhost:9100" (the port in the name is the distribution port, separate from HTTP/WS ports)
- Call `start_node()` in `start_services(pool)` as the first thing, before schema creation

Also read `MESHER_HTTP_PORT` and `MESHER_WS_PORT` via Env.get with defaults of 8080 and 8081. Use these to configure the HTTP.serve and Ws.serve calls instead of hardcoded ports. Since HTTP.serve and Ws.serve take Int ports, use `String.to_int` to parse the env var values. `String.to_int` returns `Option<Int>` -- use case match with default fallback.

Helper function pattern for env-with-default:
```
fn get_env_or_default(key :: String, default_val :: String) -> String do
  let result = Env.get(key)
  case result do
    Some(val) -> val
    None -> default_val
  end
end
```

Structure:
```
fn get_env_or_default(key, default_val) ...
fn start_node() ...
fn start_services(pool) do
  start_node()
  # ... existing schema/services/pipeline/ws/http ...
end
fn main() ...
```
  </action>
  <verify>
Run `cd /Users/sn0w/Documents/dev/snow && cargo run --bin meshc -- build mesher/ 2>&1` and confirm no NEW compilation errors beyond any pre-existing baseline. The node startup code should compile cleanly. Verify that `Node.start`, `Node.connect`, `Env.get` calls are present in the output.
  </verify>
  <done>
main.mpl reads MESHER_NODE_NAME, MESHER_COOKIE, MESHER_PEERS from environment; calls Node.start and Node.connect when configured; falls back to standalone mode when env vars are absent; HTTP and WS ports are configurable via MESHER_HTTP_PORT and MESHER_WS_PORT with defaults of 8080 and 8081.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add global service registration to pipeline.mpl</name>
  <files>mesher/ingestion/pipeline.mpl</files>
  <action>
Modify `start_pipeline(pool)` in `pipeline.mpl` to register the PipelineRegistry globally after the existing `Process.register("mesher_registry", registry_pid)` call.

Add a helper function `register_global_services(registry_pid)` defined BEFORE `start_pipeline` (define-before-use):

```
fn register_global_services(registry_pid) do
  let node_name = Node.self()
  if node_name != "" do
    # Register with node-specific name for targeted cross-node lookup
    let _ = Global.register("mesher_registry@" <> node_name, registry_pid)
    # Register a well-known default name (first-writer-wins; Global.register rejects duplicates)
    let _ = Global.register("mesher_registry", registry_pid)
    println("[Mesher] Services registered globally as mesher_registry@" <> node_name)
  else
    println("[Mesher] Running in standalone mode (skipping global registration)")
  end
end
```

Key points:
- `Node.self()` returns `String` -- empty string when not in distributed mode (Node.start not called)
- `Global.register(name, pid)` returns Int (0 success, 1 error for duplicate). Ignore the return value with `let _`.
- The node-specific name `"mesher_registry@<node_name>"` allows other nodes to find THIS node's specific registry
- The well-known name `"mesher_registry"` is a convenience -- only the first node to register wins; others silently fail (expected behavior)
- Keep the existing `Process.register("mesher_registry", registry_pid)` call -- local lookup must still work for handlers on this node

Call `register_global_services(registry_pid)` immediately after the `Process.register` line inside `start_pipeline`.

Also modify the `restart_all_services` function to call `register_global_services` after its `Process.register` call, so that global registration is restored on restart.

Do NOT modify any `Process.whereis("stream_manager")` calls -- StreamManager must remain node-local (connection handles are local pointers, per research pitfall 2).
  </action>
  <verify>
Run `cd /Users/sn0w/Documents/dev/snow && cargo run --bin meshc -- build mesher/ 2>&1` and confirm no NEW compilation errors. Verify `Global.register` and `Node.self` calls are present in pipeline.mpl.
  </verify>
  <done>
pipeline.mpl registers PipelineRegistry globally with both a node-specific name and a well-known default name when running in distributed mode; skips global registration gracefully in standalone mode; restart_all_services also re-registers globally.
  </done>
</task>

</tasks>

<verification>
1. `meshc build mesher/` compiles with no new errors beyond pre-existing baseline
2. The string "Node.start" appears in main.mpl
3. The string "Global.register" appears in pipeline.mpl
4. The string "Env.get" appears in main.mpl (env-based configuration)
5. Standalone mode: when MESHER_NODE_NAME is not set, the application behaves identically to before (all Process.whereis calls still work, services start normally)
6. Distributed mode: when MESHER_NODE_NAME and MESHER_COOKIE are set, Node.start is called and services are registered globally
</verification>

<success_criteria>
- Mesher compiles and the new node startup + global registration code is syntactically correct
- Environment variable configuration works for node name, cookie, peers, and ports
- Global.register is called for PipelineRegistry in distributed mode
- Standalone mode is the default when env vars are absent (backward compatible)
- No changes to StreamManager registration (kept node-local)
</success_criteria>

<output>
After completion, create `.planning/phases/94-multi-node-clustering/94-01-SUMMARY.md`
</output>
