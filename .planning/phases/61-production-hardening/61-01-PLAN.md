---
phase: 61-production-hardening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/snow-rt/src/ws/mod.rs
  - crates/snow-rt/src/ws/server.rs
  - crates/snow-rt/src/ws/frame.rs
  - crates/snow-rt/src/ws/close.rs
  - crates/snow-rt/src/http/server.rs
autonomous: true

must_haves:
  truths:
    - "WsStream enum abstracts over plain TcpStream and TLS StreamOwned, implementing Read + Write"
    - "snow_ws_serve_tls accepts cert/key paths, builds TLS config via build_server_config, and wraps accepted connections in WsStream::Tls"
    - "Existing snow_ws_serve still works by wrapping TcpStream in WsStream::Plain"
    - "Reader thread sends periodic Ping frames (30s default) and detects dead connections by Pong timeout (10s default)"
    - "Reader thread validates Pong payload matches sent Ping payload before resetting heartbeat timer"
    - "Reader thread reassembles fragmented messages (continuation frames) into complete messages before delivering to mailbox"
    - "Control frames (ping/pong/close) are handled inline during fragment reassembly without corrupting fragment state"
    - "Fragmented messages exceeding 16 MiB are rejected with close code 1009"
    - "MAX_PAYLOAD_SIZE in frame.rs reduced from 64 MiB to 16 MiB"
    - "UTF-8 validation for fragmented text messages happens on the fully reassembled payload, not individual fragments"
  artifacts:
    - path: "crates/snow-rt/src/ws/server.rs"
      provides: "WsStream enum, snow_ws_serve_tls, HeartbeatState, FragmentState, unified reader_thread_loop"
      contains: "WsStream"
    - path: "crates/snow-rt/src/ws/frame.rs"
      provides: "16 MiB MAX_PAYLOAD_SIZE"
      contains: "16 * 1024 * 1024"
    - path: "crates/snow-rt/src/http/server.rs"
      provides: "pub(crate) build_server_config"
      contains: "pub(crate) fn build_server_config"
  key_links:
    - from: "crates/snow-rt/src/ws/server.rs"
      to: "crates/snow-rt/src/http/server.rs"
      via: "use crate::http::server::build_server_config"
      pattern: "build_server_config"
    - from: "crates/snow-rt/src/ws/server.rs"
      to: "crates/snow-rt/src/ws/frame.rs"
      via: "read_frame/write_frame generic over Read/Write"
      pattern: "read_frame|write_frame"
---

<objective>
Add TLS support (wss://), ping/pong heartbeat, and fragment reassembly to the WebSocket server runtime.

Purpose: Make WebSocket connections production-ready with encryption, dead connection detection, and large message support. All three features modify the reader thread loop in server.rs and share the WsStream abstraction.

Output: WsStream enum, snow_ws_serve_tls entry point, HeartbeatState/FragmentState structs, unified reader thread loop with heartbeat and fragmentation, 16 MiB payload limit.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/61-production-hardening/61-RESEARCH.md
@.planning/phases/60-actor-integration/60-01-SUMMARY.md
@crates/snow-rt/src/ws/server.rs
@crates/snow-rt/src/ws/frame.rs
@crates/snow-rt/src/ws/close.rs
@crates/snow-rt/src/ws/mod.rs
@crates/snow-rt/src/http/server.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Introduce WsStream enum and snow_ws_serve_tls</name>
  <files>
    crates/snow-rt/src/ws/server.rs
    crates/snow-rt/src/ws/mod.rs
    crates/snow-rt/src/ws/frame.rs
    crates/snow-rt/src/http/server.rs
  </files>
  <action>
This task introduces the WsStream abstraction, refactors the existing server to use it, adds TLS serving, and tightens the payload limit.

**1. Make build_server_config pub(crate) in http/server.rs (line 78):**
Change `fn build_server_config(` to `pub(crate) fn build_server_config(` -- one-word change. This lets ws/server.rs import it without duplication.

**2. Reduce MAX_PAYLOAD_SIZE in frame.rs (line 14):**
Change `const MAX_PAYLOAD_SIZE: u64 = 64 * 1024 * 1024;` to `const MAX_PAYLOAD_SIZE: u64 = 16 * 1024 * 1024;`. Update the comment to say "16 MiB production limit" instead of "Phase 61 will tighten".

**3. Add WsStream enum to server.rs:**
Define at the top of server.rs (after the imports):

```rust
use std::io::{Read, Write};
use rustls::{ServerConfig, ServerConnection, StreamOwned};

/// Stream abstraction for plain TCP and TLS WebSocket connections.
/// Mirrors HttpStream in http/server.rs. Both variants implement Read + Write.
enum WsStream {
    Plain(TcpStream),
    Tls(StreamOwned<ServerConnection, TcpStream>),
}

impl Read for WsStream {
    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {
        match self {
            WsStream::Plain(s) => s.read(buf),
            WsStream::Tls(s) => s.read(buf),
        }
    }
}

impl Write for WsStream {
    fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {
        match self {
            WsStream::Plain(s) => s.write(buf),
            WsStream::Tls(s) => s.write(buf),
        }
    }
    fn flush(&mut self) -> std::io::Result<()> {
        match self {
            WsStream::Plain(s) => s.flush(),
            WsStream::Tls(s) => s.flush(),
        }
    }
}
```

**4. Refactor WsConnection to use Arc<Mutex<WsStream>> instead of Arc<Mutex<TcpStream>>:**
```rust
struct WsConnection {
    write_stream: Arc<Mutex<WsStream>>,
    shutdown: Arc<AtomicBool>,
}
```

**5. Refactor snow_ws_serve to use WsStream::Plain:**
In the accept loop, wrap the TcpStream in WsStream::Plain before boxing:
```rust
let ws_stream = WsStream::Plain(tcp_stream);
let stream_ptr = Box::into_raw(Box::new(ws_stream)) as usize;
```
Remove `tcp_stream.set_read_timeout(Some(Duration::from_secs(30))).ok();` from the accept loop -- the read timeout will be set inside the actor entry function after handshake, same as before.

**6. Refactor ws_connection_entry to use WsStream:**
Change `let mut stream = unsafe { *Box::from_raw(args.stream_ptr as *mut TcpStream) };` to `let mut stream = unsafe { *Box::from_raw(args.stream_ptr as *mut WsStream) };`.

The handshake (`perform_upgrade`) takes `&mut impl Read + Write`, so WsStream works directly. After handshake, wrap the stream in `Arc<Mutex<WsStream>>`:
```rust
let stream = Arc::new(Mutex::new(stream));
```

For the reader thread, instead of `try_clone()`, pass `Arc::clone(&stream)`. The reader thread locks the mutex for each `read_frame` call and releases between frames. Remove the `try_clone()` call entirely.

Set the read timeout BEFORE creating the WsStream. For WsStream::Plain, the read timeout was already set in snow_ws_serve. For WsStream::Tls, the timeout is set on the raw TcpStream before wrapping in StreamOwned (see step 7).

Update the `WsConnection` creation to use the shared `Arc<Mutex<WsStream>>`:
```rust
let conn = Box::into_raw(Box::new(WsConnection {
    write_stream: stream.clone(),
    shutdown: shutdown.clone(),
}));
```

The reader thread loop signature changes to take `Arc<Mutex<WsStream>>` instead of separate read/write streams.

**7. Add snow_ws_serve_tls:**
Following the snow_http_serve_tls pattern exactly (see http/server.rs lines 473-557):

```rust
#[no_mangle]
pub extern "C" fn snow_ws_serve_tls(
    on_connect_fn: *mut u8,
    on_connect_env: *mut u8,
    on_message_fn: *mut u8,
    on_message_env: *mut u8,
    on_close_fn: *mut u8,
    on_close_env: *mut u8,
    port: i64,
    cert_path: *const SnowString,
    key_path: *const SnowString,
) {
    crate::actor::snow_rt_init_actor(0);

    let cert_str = unsafe { (*cert_path).as_str() };
    let key_str = unsafe { (*key_path).as_str() };

    let tls_config = match crate::http::server::build_server_config(cert_str, key_str) {
        Ok(c) => c,
        Err(e) => {
            eprintln!("[snow-rt] Failed to load TLS certificates: {}", e);
            return;
        }
    };

    let addr = format!("0.0.0.0:{}", port);
    let listener = match TcpListener::bind(&addr) {
        Ok(l) => l,
        Err(e) => {
            eprintln!("[snow-rt] Failed to start WebSocket TLS server on {}: {}", addr, e);
            return;
        }
    };

    eprintln!("[snow-rt] WebSocket TLS server listening on {}", addr);

    let config_ptr = Arc::into_raw(tls_config) as usize;

    for tcp_stream in listener.incoming() {
        let tcp_stream = match tcp_stream {
            Ok(s) => s,
            Err(e) => {
                eprintln!("[snow-rt] accept error: {}", e);
                continue;
            }
        };

        // Set read timeout BEFORE TLS wrapping (Pitfall 1 from research)
        tcp_stream.set_read_timeout(Some(Duration::from_secs(5))).ok();

        let tls_config = unsafe { Arc::from_raw(config_ptr as *const ServerConfig) };
        let conn = match ServerConnection::new(Arc::clone(&tls_config)) {
            Ok(c) => c,
            Err(e) => {
                eprintln!("[snow-rt] TLS connection setup failed: {}", e);
                std::mem::forget(tls_config);
                continue;
            }
        };
        std::mem::forget(tls_config);

        let tls_stream = StreamOwned::new(conn, tcp_stream);
        let ws_stream = WsStream::Tls(tls_stream);

        let handler = WsHandler {
            on_connect_fn, on_connect_env,
            on_message_fn, on_message_env,
            on_close_fn, on_close_env,
        };
        let stream_ptr = Box::into_raw(Box::new(ws_stream)) as usize;
        let args = WsConnectionArgs { handler, stream_ptr };
        let args_ptr = Box::into_raw(Box::new(args)) as *const u8;
        let args_size = std::mem::size_of::<WsConnectionArgs>() as u64;

        let sched = global_scheduler();
        sched.spawn(
            ws_connection_entry as *const u8,
            args_ptr,
            args_size,
            1,
        );
    }
}
```

**8. Update snow_ws_send and snow_ws_send_binary:**
These already use `conn.write_stream.lock()` which now returns `MutexGuard<WsStream>`. Since `write_frame` is generic over `Write`, this compiles without change. Just verify the types are correct.

**9. Update reader_thread_loop signature:**
The new signature takes a single `Arc<Mutex<WsStream>>` instead of separate read and write streams:
```rust
fn reader_thread_loop(
    stream: Arc<Mutex<WsStream>>,
    proc_arc: Arc<Mutex<Process>>,
    actor_pid: ProcessId,
    shutdown: Arc<AtomicBool>,
) {
```
The loop body locks `stream` for each `read_frame` call and for control frame writes. The lock is released between frames. This is the same pattern as the current `write_stream` mutex but now also covers reads.

**10. Update mod.rs:**
Add `pub use server::snow_ws_serve_tls;` if needed for external visibility (check if other serve functions need pub re-export -- they are `#[no_mangle] pub extern "C"` so LLVM links them directly; no Rust re-export needed).

**IMPORTANT: Do NOT implement heartbeat or fragmentation in this task.** The reader thread loop should remain functionally identical to the current one, just using the unified WsStream. Heartbeat and fragmentation are Task 2.
  </action>
  <verify>
    - `cargo check -p snow-rt` compiles with no errors
    - `cargo test -p snow-rt ws::` -- all existing WS tests pass (tests use plain TCP, so WsStream::Plain path is exercised)
    - `cargo test -p snow-rt actor::` -- no regressions in actor tests
    - Grep for `try_clone` in server.rs -- should be gone (unified mutex path)
    - Grep for `WsStream` in server.rs -- enum and both variants present
    - Grep for `build_server_config` in server.rs -- imported from http::server
    - Grep for `16 * 1024 * 1024` in frame.rs -- confirms limit change
  </verify>
  <done>
    WsStream enum defined with Plain/Tls variants implementing Read+Write. snow_ws_serve uses WsStream::Plain, snow_ws_serve_tls uses WsStream::Tls with rustls. Reader thread uses Arc<Mutex<WsStream>> for unified read/write access. build_server_config is pub(crate). MAX_PAYLOAD_SIZE is 16 MiB. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add heartbeat ping/pong and fragment reassembly to reader thread</name>
  <files>
    crates/snow-rt/src/ws/server.rs
  </files>
  <action>
This task adds the HeartbeatState and FragmentState structs and integrates them into the reader thread loop.

**1. Add HeartbeatState struct:**
```rust
use std::time::Instant;

/// Tracks ping/pong heartbeat state for dead connection detection.
struct HeartbeatState {
    last_ping_sent: Instant,
    last_pong_received: Instant,
    ping_interval: Duration,       // default 30s
    pong_timeout: Duration,        // default 10s
    pending_ping_payload: Option<[u8; 4]>,
}

impl HeartbeatState {
    fn new() -> Self {
        let now = Instant::now();
        Self {
            last_ping_sent: now,
            last_pong_received: now,
            ping_interval: Duration::from_secs(30),
            pong_timeout: Duration::from_secs(10),
            pending_ping_payload: None,
        }
    }

    fn should_send_ping(&self) -> bool {
        self.last_ping_sent.elapsed() >= self.ping_interval
    }

    fn is_pong_overdue(&self) -> bool {
        if self.pending_ping_payload.is_some() {
            self.last_ping_sent.elapsed() >= self.pong_timeout
        } else {
            false
        }
    }
}
```

**2. Add FragmentState struct and ReassembleResult enum:**
```rust
/// Tracks fragment reassembly state for continuation frames.
struct FragmentState {
    /// The opcode of the first fragment (Text or Binary). None = not in a fragment sequence.
    initial_opcode: Option<WsOpcode>,
    /// Accumulated payload bytes from all fragments so far.
    buffer: Vec<u8>,
    /// Maximum total message size (16 MiB).
    max_message_size: usize,
}

impl FragmentState {
    fn new() -> Self {
        Self {
            initial_opcode: None,
            buffer: Vec::new(),
            max_message_size: 16 * 1024 * 1024,
        }
    }

    fn is_assembling(&self) -> bool {
        self.initial_opcode.is_some()
    }
}

/// Result of feeding a data frame to the fragment reassembly state machine.
enum ReassembleResult {
    /// A complete message is ready (unfragmented or final fragment assembled).
    Complete(WsFrame),
    /// Still accumulating fragments.
    Accumulating,
    /// Total message size exceeded the limit (FRAG-03).
    TooLarge,
    /// Protocol error (e.g., new message during fragmented sequence, unexpected continuation).
    ProtocolError(&'static str),
}
```

**3. Add reassemble function:**
```rust
fn reassemble(frag: &mut FragmentState, frame: WsFrame) -> ReassembleResult {
    match frame.opcode {
        // Unfragmented message: FIN=1, data opcode, not currently assembling
        WsOpcode::Text | WsOpcode::Binary if frame.fin && !frag.is_assembling() => {
            ReassembleResult::Complete(frame)
        }
        // First fragment: FIN=0, data opcode, not currently assembling
        WsOpcode::Text | WsOpcode::Binary if !frame.fin && !frag.is_assembling() => {
            frag.initial_opcode = Some(frame.opcode);
            frag.buffer = frame.payload;
            if frag.buffer.len() > frag.max_message_size {
                frag.initial_opcode = None;
                frag.buffer.clear();
                return ReassembleResult::TooLarge;
            }
            ReassembleResult::Accumulating
        }
        // Protocol error: new message started while assembling
        WsOpcode::Text | WsOpcode::Binary if frag.is_assembling() => {
            frag.initial_opcode = None;
            frag.buffer.clear();
            ReassembleResult::ProtocolError("new message during fragmented sequence")
        }
        // Continuation fragment: FIN=0, currently assembling
        WsOpcode::Continuation if !frame.fin && frag.is_assembling() => {
            if frag.buffer.len() + frame.payload.len() > frag.max_message_size {
                frag.initial_opcode = None;
                frag.buffer.clear();
                return ReassembleResult::TooLarge;
            }
            frag.buffer.extend_from_slice(&frame.payload);
            ReassembleResult::Accumulating
        }
        // Final fragment: FIN=1, continuation, currently assembling
        WsOpcode::Continuation if frame.fin && frag.is_assembling() => {
            if frag.buffer.len() + frame.payload.len() > frag.max_message_size {
                frag.initial_opcode = None;
                frag.buffer.clear();
                return ReassembleResult::TooLarge;
            }
            frag.buffer.extend_from_slice(&frame.payload);
            let opcode = frag.initial_opcode.take().unwrap();
            let payload = std::mem::take(&mut frag.buffer);
            ReassembleResult::Complete(WsFrame {
                fin: true,
                opcode,
                payload,
            })
        }
        // Protocol error: continuation without preceding first fragment
        WsOpcode::Continuation if !frag.is_assembling() => {
            ReassembleResult::ProtocolError("unexpected continuation frame")
        }
        // Control frames should never reach reassemble (handled before this call)
        _ => ReassembleResult::ProtocolError("unexpected opcode in reassembly")
    }
}
```

**4. Rewrite reader_thread_loop with heartbeat and fragmentation:**
The reader thread loop now has this structure:

```
loop {
    if shutdown { break; }

    // HEARTBEAT: Check pong timeout (BEAT-04)
    if heartbeat.is_pong_overdue() {
        lock stream -> send_close(1001, "pong timeout")
        push_disconnect
        break
    }

    // HEARTBEAT: Send periodic ping (BEAT-01)
    if heartbeat.should_send_ping() {
        let payload = rand::random::<[u8; 4]>();
        lock stream -> write_frame(Ping, &payload, true)
        heartbeat.last_ping_sent = Instant::now();
        heartbeat.pending_ping_payload = Some(payload);
    }

    // Read a frame (lock released between frames)
    let frame_result = { lock stream -> read_frame(&mut *stream) };

    match frame_result {
        Ok(frame) => {
            // HEARTBEAT: Handle Pong BEFORE process_frame (BEAT-02, BEAT-03)
            if frame.opcode == WsOpcode::Pong {
                if let Some(expected) = heartbeat.pending_ping_payload {
                    if frame.payload == expected {
                        heartbeat.last_pong_received = Instant::now();
                        heartbeat.pending_ping_payload = None;
                    }
                }
                continue;  // Pong handled, skip to next frame
            }

            // HEARTBEAT: Auto-respond to client Ping with Pong (BEAT-02)
            // Also handles Close frames
            if matches!(frame.opcode, WsOpcode::Ping | WsOpcode::Close) {
                let mut s = stream.lock();
                match process_frame(&mut *s, frame) {
                    Ok(None) => { /* Ping -> Pong sent */ }
                    Err(_) => {
                        drop(s);
                        push_disconnect(...);
                        break;
                    }
                    _ => {}
                }
                continue;
            }

            // FRAGMENTATION: Feed data frames through reassembly (FRAG-01, FRAG-02, FRAG-03)
            match reassemble(&mut frag, frame) {
                ReassembleResult::Complete(msg) => {
                    // UTF-8 validation for text (Pitfall 6: validate on reassembled payload)
                    if msg.opcode == WsOpcode::Text {
                        if validate_text_payload(&msg.payload).is_err() {
                            let mut s = stream.lock();
                            let _ = send_close(&mut *s, WsCloseCode::INVALID_DATA, "invalid UTF-8");
                            drop(s);
                            push_disconnect(...);
                            break;
                        }
                    }
                    let tag = match msg.opcode {
                        WsOpcode::Text => WS_TEXT_TAG,
                        WsOpcode::Binary => WS_BINARY_TAG,
                        _ => WS_TEXT_TAG,
                    };
                    // Push to mailbox (existing code)
                    let buffer = MessageBuffer::new(msg.payload, tag);
                    // ... push to mailbox and wake actor ...
                }
                ReassembleResult::Accumulating => { /* waiting for more fragments */ }
                ReassembleResult::TooLarge => {
                    lock stream -> send_close(1009, "message too big")
                    push_disconnect
                    break
                }
                ReassembleResult::ProtocolError(reason) => {
                    lock stream -> send_close(1002, reason)
                    push_disconnect
                    break
                }
            }
        }
        Err(e) if timeout -> continue
        Err(_) -> push_disconnect; break
    }
}
```

**IMPORTANT notes for the reader thread rewrite:**
- Pong handling MUST happen BEFORE process_frame (research Decision 5). The existing process_frame silently ignores Pong; we need to inspect the payload.
- Client Ping -> Pong auto-response uses the existing process_frame (which calls write_frame with Pong). This satisfies BEAT-02.
- Control frames (Ping/Close) are handled inline regardless of fragment state (FRAG-02). They do NOT go through `reassemble()`.
- UTF-8 validation for text messages happens on the fully reassembled payload (Pitfall 6), not on individual fragments.
- Size limit is checked BEFORE appending each fragment (Pitfall 5) -- the `reassemble()` function checks `frag.buffer.len() + frame.payload.len() > frag.max_message_size`.
- Add `use super::close::validate_text_payload;` if not already imported.

**5. Add `rand` import for ping payload:**
Add `use rand::Rng;` or use `rand::random::<[u8; 4]>()` directly. rand 0.9 is already a dependency of snow-rt.

**6. Add WsCloseCode::MESSAGE_TOO_BIG constant:**
In close.rs, add: `pub const MESSAGE_TOO_BIG: u16 = 1009;` to WsCloseCode. This is cleaner than using a magic number.
  </action>
  <verify>
    - `cargo check -p snow-rt` compiles with no errors
    - `cargo test -p snow-rt ws::` -- all existing WS tests pass (echo test, lifecycle test, crash test, reader thread test, disconnect test)
    - Grep for `HeartbeatState` in server.rs -- struct exists
    - Grep for `FragmentState` in server.rs -- struct exists
    - Grep for `reassemble` in server.rs -- function exists
    - Grep for `is_pong_overdue` in server.rs -- heartbeat check exists in reader thread loop
    - Grep for `should_send_ping` in server.rs -- ping sending exists in reader thread loop
    - Grep for `MESSAGE_TOO_BIG` in close.rs -- constant exists
    - `cargo test -p snow-rt` -- full snow-rt test suite passes
  </verify>
  <done>
    HeartbeatState sends periodic Ping frames with random 4-byte payload (30s interval), validates Pong payload matches, closes connection after 10s Pong timeout. FragmentState reassembles continuation frames with 16 MiB limit, handles interleaved control frames, validates UTF-8 on complete reassembled text messages. Close code 1009 sent for oversized messages, 1002 for protocol errors. All existing tests pass.
  </done>
</task>

</tasks>

<verification>
1. `cargo check -p snow-rt` -- compiles
2. `cargo test -p snow-rt ws::` -- all WS tests pass
3. `cargo test -p snow-rt` -- full snow-rt suite passes
4. `cargo test --workspace` -- no regressions across crates
5. Verify WsStream enum has Plain and Tls variants
6. Verify snow_ws_serve_tls function exists and is #[no_mangle] pub extern "C"
7. Verify HeartbeatState and FragmentState structs exist
8. Verify MAX_PAYLOAD_SIZE is 16 MiB
9. Verify build_server_config is pub(crate) in http/server.rs
</verification>

<success_criteria>
- WsStream enum abstracts over plain and TLS streams
- snow_ws_serve_tls accepts the same callback pattern as snow_ws_serve plus cert/key paths
- Reader thread sends Ping, validates Pong, detects dead connections
- Fragment reassembly handles continuation frames, interleaved control frames, and 16 MiB limit
- All existing tests pass with zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/61-production-hardening/61-01-SUMMARY.md`
</output>
