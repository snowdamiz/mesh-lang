---
phase: 06-actor-runtime
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/snow-rt/Cargo.toml
  - crates/snow-rt/src/lib.rs
  - crates/snow-rt/src/actor/mod.rs
  - crates/snow-rt/src/actor/process.rs
  - crates/snow-rt/src/actor/scheduler.rs
  - crates/snow-rt/src/actor/stack.rs
autonomous: true

must_haves:
  truths:
    - "Scheduler spawns actors as lightweight stackful coroutines and runs them to completion"
    - "Work-stealing distributes actors across multiple OS threads (one per CPU core)"
    - "Each actor has its own stack (64KB default) managed by corosensei"
    - "snow_rt_init_actor() starts the scheduler and snow_actor_spawn() creates a new actor"
  artifacts:
    - path: "crates/snow-rt/src/actor/process.rs"
      provides: "Process Control Block (PCB) with state, stack, reduction counter, priority"
      contains: "pub struct Process"
    - path: "crates/snow-rt/src/actor/scheduler.rs"
      provides: "M:N work-stealing scheduler using crossbeam-deque"
      contains: "pub struct Scheduler"
    - path: "crates/snow-rt/src/actor/stack.rs"
      provides: "Corosensei-based stackful coroutine management"
      contains: "corosensei"
    - path: "crates/snow-rt/src/actor/mod.rs"
      provides: "Actor module entry, extern C functions for spawn/init"
      contains: "snow_actor_spawn"
  key_links:
    - from: "crates/snow-rt/src/actor/scheduler.rs"
      to: "crossbeam-deque"
      via: "Worker/Stealer deques for work-stealing"
      pattern: "crossbeam_deque"
    - from: "crates/snow-rt/src/actor/stack.rs"
      to: "corosensei"
      via: "ScopedCoroutine for context switching"
      pattern: "corosensei"
    - from: "crates/snow-rt/src/actor/mod.rs"
      to: "crates/snow-rt/src/actor/scheduler.rs"
      via: "snow_actor_spawn enqueues process into scheduler"
      pattern: "scheduler.*spawn\\|enqueue"
---

<objective>
Build the core actor runtime: Process Control Block, M:N work-stealing scheduler, and stackful coroutine management using corosensei. All in Rust, tested standalone without compiler integration.

Purpose: The scheduler is the foundation of the entire actor system. Actors are lightweight processes multiplexed across OS threads via work-stealing. This plan delivers the ability to spawn actors that run functions, get preempted (via reduction counting), and complete -- all tested in pure Rust unit/integration tests.

Output: snow-rt/src/actor/ module with PCB, scheduler, stack management, and extern "C" entry points (snow_rt_init_actor, snow_actor_spawn, snow_reduction_check, snow_actor_self).
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-actor-runtime/06-RESEARCH.md
@crates/snow-rt/src/lib.rs
@crates/snow-rt/Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add actor runtime dependencies and create Process Control Block</name>
  <files>
    crates/snow-rt/Cargo.toml
    crates/snow-rt/src/actor/mod.rs
    crates/snow-rt/src/actor/process.rs
  </files>
  <action>
Add new dependencies to snow-rt/Cargo.toml:
```toml
[dependencies]
crossbeam-deque = "0.8"
crossbeam-utils = "0.8"
crossbeam-channel = "0.5"
corosensei = "0.3"
parking_lot = "0.12"
rustc-hash = { workspace = true }
```

Create `crates/snow-rt/src/actor/mod.rs` as the actor module entry point. Re-export key types.

Create `crates/snow-rt/src/actor/process.rs` with:

1. **ProcessId**: A `u64` newtype for actor PIDs. Use AtomicU64 global counter for unique ID generation.

2. **ProcessState** enum: `Ready`, `Running`, `Waiting` (blocked on receive), `Exited(ExitReason)`.

3. **ExitReason** enum: `Normal`, `Error(String)`, `Killed`, `Linked(ProcessId, Box<ExitReason>)`.

4. **Priority** enum: `High`, `Normal`, `Low` (per user decision: basic priority levels).

5. **Process** struct (the PCB):
   - `pid: ProcessId`
   - `state: ProcessState`
   - `priority: Priority`
   - `reductions: u32` (starts at 4000 per research recommendation)
   - `links: Vec<ProcessId>` (linked processes -- empty initially, populated in Plan 06)
   - `mailbox: VecDeque<Message>` (FIFO mailbox -- populated in Plan 03)
   - A handle/reference to its coroutine stack (initially a placeholder type that Plan 01 Task 2 fills in)

6. **Message** struct: For now, a placeholder `pub struct Message { pub data: Vec<u8>, pub type_tag: u64 }` that Plan 03 will flesh out with proper deep-copy semantics.

7. **DEFAULT_REDUCTIONS**: `pub const DEFAULT_REDUCTIONS: u32 = 4000;`

All fields should be `pub` for cross-module access within snow-rt. Derive Debug on all types.

Do NOT implement mailbox operations (Plan 03), linking operations (Plan 06), or GC integration (Plan 03). This task focuses purely on the data structures.
  </action>
  <verify>
`cargo build -p snow-rt` compiles successfully. `cargo test -p snow-rt` passes (existing tests still green + any new unit tests for ProcessId generation uniqueness).
  </verify>
  <done>Process struct exists with all fields. ProcessId generates unique IDs atomically. ProcessState and Priority enums defined. Message placeholder exists. snow-rt builds with all new dependencies.</done>
</task>

<task type="auto">
  <name>Task 2: Implement M:N work-stealing scheduler with corosensei coroutines</name>
  <files>
    crates/snow-rt/src/actor/scheduler.rs
    crates/snow-rt/src/actor/stack.rs
    crates/snow-rt/src/actor/mod.rs
    crates/snow-rt/src/lib.rs
  </files>
  <action>
Create `crates/snow-rt/src/actor/stack.rs`:
- Use `corosensei::ScopedCoroutine` for stackful coroutine context switching.
- Define a `CoroutineHandle` type wrapping corosensei's coroutine with a 64KB stack.
- Implement `new(entry_fn: fn_ptr, args)` that creates a new coroutine. The entry function receives a `Yielder` reference which it stores in a thread-local for `snow_reduction_check` to access.
- Implement `resume()` that resumes the coroutine (returns when it yields or completes).
- Thread-local `CURRENT_YIELDER: Option<*const Yielder>` for snow_reduction_check to call yield.
- Thread-local `CURRENT_PID: Option<ProcessId>` for `snow_actor_self()`.

Create `crates/snow-rt/src/actor/scheduler.rs`:
- `Scheduler` struct with:
  - `workers: Vec<Worker<Arc<Mutex<Process>>>>` (crossbeam-deque local Worker deques)
  - `stealers: Vec<Stealer<Arc<Mutex<Process>>>>` (one Stealer per worker for cross-thread stealing)
  - `global_queue: crossbeam_channel::Sender/Receiver<Arc<Mutex<Process>>>` for new spawns and overflow
  - `num_threads: usize` (default: number of CPU cores, via `std::thread::available_parallelism()`)
  - Process table: `Arc<parking_lot::RwLock<FxHashMap<ProcessId, Arc<Mutex<Process>>>>>` for PID lookup
- `Scheduler::new(num_threads: u32)` -- creates worker/stealer pairs and global channel.
- `Scheduler::spawn(fn_ptr: *const u8, args: *const u8, args_size: u64, priority: u8) -> ProcessId`:
  - Creates a new Process with unique PID
  - Creates a CoroutineHandle for the entry function
  - Pushes onto global queue
  - Returns the PID
- `Scheduler::run()`:
  - Spawns `num_threads` OS threads via `std::thread::spawn` (or `crossbeam_utils::thread::scope` for scoped threads)
  - Each thread runs `worker_loop`:
    1. Pop from local deque (LIFO for locality)
    2. If empty, try pop from global queue
    3. If empty, steal from random other worker (crossbeam Steal::retry loop)
    4. If got a process: set thread-local CURRENT_PID, resume its coroutine
    5. After resume: if process yielded (reductions exhausted), reset reductions to DEFAULT_REDUCTIONS, re-enqueue; if process completed, mark state Exited(Normal)
    6. High-priority processes: check a separate high-priority queue first
  - Run until all processes have exited (main process signals shutdown)
- The "main" actor: `snow_rt_init_actor` wraps the caller's main function as the first actor (PID 0 or 1). When it exits, signal scheduler shutdown.

Update `crates/snow-rt/src/actor/mod.rs`:
- `#[no_mangle] pub extern "C" fn snow_rt_init_actor(num_schedulers: u32)` -- initializes the global scheduler. If num_schedulers == 0, use available_parallelism().
- `#[no_mangle] pub extern "C" fn snow_actor_spawn(fn_ptr: *const u8, args: *const u8, args_size: u64, priority: u8) -> u64` -- delegates to scheduler.spawn(), returns PID as u64.
- `#[no_mangle] pub extern "C" fn snow_actor_self() -> u64` -- reads thread-local CURRENT_PID, returns PID as u64.
- `#[no_mangle] pub extern "C" fn snow_reduction_check()` -- decrements current actor's reduction counter. If zero: reset to DEFAULT_REDUCTIONS, yield via thread-local Yielder.
- Store the global scheduler in a `static` (use `parking_lot::Mutex<Option<Scheduler>>` or `OnceLock`).

Update `crates/snow-rt/src/lib.rs`:
- Add `pub mod actor;`
- Re-export the extern "C" functions: snow_rt_init_actor, snow_actor_spawn, snow_actor_self, snow_reduction_check.

Write unit tests:
- Test that spawn creates unique PIDs
- Test that a single actor runs to completion
- Test that multiple actors all complete (spawn 10 actors, each increments an AtomicU64, verify final count == 10)
- Test that work-stealing distributes across threads (spawn 100 actors, verify they run on multiple threads by recording thread IDs)
- Test that reduction_check causes yield (an actor that loops should still allow other actors to run)

IMPORTANT implementation notes:
- The actor entry function signature for Phase 6 is `extern "C" fn(args: *const u8)`. The compiled Snow actor code will be wrapped to match this.
- Use `corosensei::ScopedCoroutine` (not the unsafe `Coroutine`) for memory safety.
- Start with 64KB stacks. Virtual memory will handle 100K actors via lazy page commit.
- For shutdown: when the main actor (first spawned) exits, set a global `AtomicBool` shutdown flag. Worker threads check this flag in their loop.
- Priority: Check high-priority queue before normal deque. Low-priority actors go to end of global queue. Keep it simple -- 3 priority levels is sufficient.
  </action>
  <verify>
`cargo test -p snow-rt` passes all tests. Specifically verify:
- `test_spawn_unique_pids` -- 10 spawned actors get 10 different PIDs
- `test_single_actor_completes` -- actor runs entry function and exits
- `test_multiple_actors_complete` -- 10+ actors all run
- `test_work_stealing` -- actors execute on multiple OS threads
- `test_reduction_yield` -- tight-loop actor does not starve others
All existing snow-rt tests (GC, string, panic) still pass.
  </verify>
  <done>M:N scheduler spawns actors as corosensei coroutines across CPU cores. Work-stealing distributes load. Reduction counting preempts actors after 4000 reductions. snow_rt_init_actor, snow_actor_spawn, snow_actor_self, snow_reduction_check are exported as extern "C" functions. At least 5 unit tests verify core behavior.</done>
</task>

</tasks>

<verification>
- `cargo build -p snow-rt` succeeds with all new dependencies
- `cargo test -p snow-rt` passes all existing + new tests
- `cargo test -p snow-rt -- --test-threads=1` also passes (tests are thread-safe)
- The scheduler can spawn and complete 100+ actors without hanging or crashing
- No regressions in workspace: `cargo test --workspace` passes
</verification>

<success_criteria>
1. Process Control Block defined with pid, state, priority, reductions, links, mailbox
2. M:N scheduler runs on N OS threads with crossbeam-deque work-stealing
3. Actors run as stackful coroutines via corosensei with 64KB stacks
4. Reduction counting causes actor yield after 4000 reductions
5. extern "C" ABI functions exported: snow_rt_init_actor, snow_actor_spawn, snow_actor_self, snow_reduction_check
6. All tests pass including multi-actor concurrency tests
</success_criteria>

<output>
After completion, create `.planning/phases/06-actor-runtime/06-01-SUMMARY.md`
</output>
