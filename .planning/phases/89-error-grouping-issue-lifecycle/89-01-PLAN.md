---
phase: 89-error-grouping-issue-lifecycle
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mesher/ingestion/fingerprint.mpl
  - mesher/storage/queries.mpl
  - mesher/storage/writer.mpl
  - mesher/services/event_processor.mpl
autonomous: true

must_haves:
  truths:
    - "System computes fingerprints from stack trace frames (file + function + normalized message)"
    - "System falls back to exception type then raw message when no stack trace is present"
    - "System respects user-provided custom fingerprint overrides"
    - "First occurrence of a fingerprint creates a new Issue"
    - "Subsequent events with same fingerprint increment event_count and update last_seen"
    - "System detects regressions when a resolved issue receives a new event (flips to unresolved)"
  artifacts:
    - path: "mesher/ingestion/fingerprint.mpl"
      provides: "Fingerprint computation with fallback chain"
      contains: "compute_fingerprint"
    - path: "mesher/storage/queries.mpl"
      provides: "Issue upsert with regression detection"
      contains: "upsert_issue"
    - path: "mesher/storage/writer.mpl"
      provides: "Modified insert_event accepting issue_id and fingerprint as separate params"
      contains: "insert_event"
    - path: "mesher/services/event_processor.mpl"
      provides: "Enriched event processing: fingerprint -> upsert -> store"
      contains: "route_event"
  key_links:
    - from: "mesher/services/event_processor.mpl"
      to: "mesher/ingestion/fingerprint.mpl"
      via: "import and call compute_fingerprint"
      pattern: "compute_fingerprint"
    - from: "mesher/services/event_processor.mpl"
      to: "mesher/storage/queries.mpl"
      via: "import and call upsert_issue"
      pattern: "upsert_issue"
    - from: "mesher/services/event_processor.mpl"
      to: "mesher/storage/writer.mpl"
      via: "StorageWriter.store with enriched params"
      pattern: "StorageWriter\\.store"
---

<objective>
Implement fingerprint computation, issue upsert with regression detection, and enrich the EventProcessor to compute fingerprints and create/update issues before storing events.

Purpose: Events must be grouped into issues via server-side fingerprinting before storage. This is the core grouping pipeline that all issue management depends on.
Output: Fingerprint module, issue upsert query, modified insert_event, enriched EventProcessor.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/89-error-grouping-issue-lifecycle/89-RESEARCH.md

Source files to read before implementing:
@mesher/types/event.mpl
@mesher/types/issue.mpl
@mesher/storage/queries.mpl
@mesher/storage/writer.mpl
@mesher/services/event_processor.mpl
@mesher/services/writer.mpl
@mesher/ingestion/pipeline.mpl
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fingerprint computation module and issue upsert query</name>
  <files>mesher/ingestion/fingerprint.mpl, mesher/storage/queries.mpl</files>
  <action>
**Create `mesher/ingestion/fingerprint.mpl`** -- a new module with the fingerprint computation logic.

Import `from Types.Event import EventPayload, StackFrame, ExceptionInfo`.

Implement these pub functions:

1. `pub fn compute_fingerprint(payload :: EventPayload) -> String` -- Main entry point. Fallback chain:
   - Priority 1: If `String.length(payload.fingerprint) > 0`, return `payload.fingerprint` (custom override, GROUP-03).
   - Priority 2: Call `compute_from_stacktrace_or_fallback(payload)`.

2. `fn compute_from_stacktrace_or_fallback(payload :: EventPayload) -> String` -- Case match on `payload.stacktrace`:
   - `Some(frames)` -> compute `fingerprint_from_frames(frames, payload.message)`. If result has `String.length > 0`, return it; else call `fallback_fingerprint(payload)`.
   - `None` -> call `fallback_fingerprint(payload)`.

3. `fn fallback_fingerprint(payload :: EventPayload) -> String` -- Case match on `payload.exception`:
   - `Some(exc)` -> return `exc.type_name <> ":" <> normalize_message(exc.value)` (GROUP-02 exception fallback).
   - `None` -> return `"msg:" <> normalize_message(payload.message)` (GROUP-02 message fallback).

4. `fn fingerprint_from_frames(frames :: List<StackFrame>, msg :: String) -> String` -- Use recursive helper `fingerprint_frames_loop(frames, "", 0, List.length(frames), msg)`. Build string of `filename|function_name` joined by `;`, appended with `:` + `normalize_message(msg)`. Do NOT include line numbers (they change with unrelated edits). GROUP-01.

5. `fn fingerprint_frames_loop(frames, acc :: String, i :: Int, total :: Int, msg :: String) -> String` -- Recursive loop (Mesh has no mutable variables). At each step: `let frame = List.get(frames, i)`, `let part = frame.filename <> "|" <> frame.function_name`. If `String.length(acc) > 0` then `acc <> ";" <> part` else `part`. Base case: return `acc <> ":" <> normalize_message(msg)`.

6. `fn normalize_message(msg :: String) -> String` -- `String.trim(String.to_lower(String.replace(msg, "0x", "")))`. Simple normalization: lowercase and strip hex prefixes. Full regex not available in Mesh.

**Extend `mesher/storage/queries.mpl`** -- Add issue upsert and discard check queries.

Add import: `from Types.Issue import Issue` (already imported).

Add these pub functions:

1. `pub fn upsert_issue(pool :: PoolHandle, project_id :: String, fingerprint :: String, title :: String, level :: String) -> String!String` -- Uses PostgreSQL ON CONFLICT upsert (atomic, no race conditions). SQL:
   ```sql
   INSERT INTO issues (project_id, fingerprint, title, level, event_count)
   VALUES ($1::uuid, $2, $3, $4, 1)
   ON CONFLICT (project_id, fingerprint)
   DO UPDATE SET event_count = issues.event_count + 1,
                 last_seen = now(),
                 status = CASE WHEN issues.status = 'resolved' THEN 'unresolved' ELSE issues.status END
   RETURNING id::text, status
   ```
   This handles GROUP-04 (new issue on first occurrence), GROUP-05 (track event_count + last_seen), and ISSUE-02 (regression detection -- resolved flips to unresolved). Returns Ok(issue_id) or Err.

2. `pub fn is_issue_discarded(pool :: PoolHandle, project_id :: String, fingerprint :: String) -> Bool!String` -- Query: `SELECT status FROM issues WHERE project_id = $1::uuid AND fingerprint = $2 AND status = 'discarded'`. Return `true` if rows found, `false` otherwise. Used by EventProcessor to skip events for discarded fingerprints (ISSUE-05 suppression).

Follow existing query patterns in queries.mpl: Pool.query with `?` operator, Map.get on rows, List.length/List.head checks.
  </action>
  <verify>
Run `cd /Users/sn0w/Documents/dev/snow && cargo build --release 2>&1 | tail -20` to verify Mesh compiles with the new fingerprint module and extended queries. The build must succeed (exit code 0). If import resolution errors occur, check module path conventions (Ingestion.Fingerprint for mesher/ingestion/fingerprint.mpl).
  </verify>
  <done>
Fingerprint module exists at mesher/ingestion/fingerprint.mpl with compute_fingerprint implementing the full fallback chain (custom > stacktrace > exception > message). Issue upsert query exists in queries.mpl with ON CONFLICT regression detection. Discard check query exists. Project compiles.
  </done>
</task>

<task type="auto">
  <name>Task 2: Enrich EventProcessor and modify insert_event for issue_id injection</name>
  <files>mesher/storage/writer.mpl, mesher/services/event_processor.mpl</files>
  <action>
**Modify `mesher/storage/writer.mpl`** -- Change `insert_event` to accept `issue_id` and `fingerprint` as separate SQL parameters instead of extracting them from JSON. This is research Open Question 1, Option B (cleaner, avoids JSON manipulation in Mesh).

Change the function signature to:
```
pub fn insert_event(pool :: PoolHandle, project_id :: String, issue_id :: String, fingerprint :: String, json_str :: String) -> Int!String
```

Update the SQL to use `$2::uuid` for issue_id and `$3` for fingerprint, with `$4::jsonb` for the JSON payload (shifted parameter positions):
```sql
INSERT INTO events (project_id, issue_id, level, message, fingerprint, exception, stacktrace, breadcrumbs, tags, extra, user_context, sdk_name, sdk_version)
SELECT $1::uuid, $2::uuid, j->>'level', j->>'message', $3, (j->'exception')::jsonb, (j->'stacktrace')::jsonb, (j->'breadcrumbs')::jsonb, COALESCE((j->'tags')::jsonb, '{}'::jsonb), COALESCE((j->'extra')::jsonb, '{}'::jsonb), (j->'user_context')::jsonb, j->>'sdk_name', j->>'sdk_version'
FROM (SELECT $4::jsonb AS j) AS sub
```
Parameters: `[project_id, issue_id, fingerprint, json_str]`.

**Modify `mesher/services/writer.mpl`** (the StorageWriter service) -- Update `flush_loop` to pass the new parameters. Since StorageWriter receives buffered event strings, the issue_id and fingerprint must be embedded in what it receives. Change the buffer to store tuples-as-delimited-strings: the EventProcessor will send a composite string `issue_id <> "\t" <> fingerprint <> "\t" <> event_json`. In `flush_loop`, split each entry: `let parts = String.split(entry, "\t")`, extract `issue_id = List.get(parts, 0)`, `fingerprint = List.get(parts, 1)`, `event_json = List.get(parts, 2)`. Pass all four params to `insert_event(pool, project_id, issue_id, fingerprint, event_json)`.

Wait -- `insert_event` is in `Storage.Writer` (storage/writer.mpl), but the StorageWriter SERVICE is in `Services.Writer` (services/writer.mpl). The service's `flush_loop` calls `insert_event`. The service already imports `from Storage.Writer import insert_event`. Update the call in `flush_loop` to pass the additional params after splitting.

**Modify `mesher/services/event_processor.mpl`** -- This is the critical wiring. The EventProcessor must:
1. Import `from Ingestion.Fingerprint import compute_fingerprint`
2. Import `from Storage.Queries import upsert_issue, is_issue_discarded`
3. Import `from Types.Event import EventPayload` (for JSON map field extraction -- but cross-module from_json does not work per decision [88-02])

Since EventPayload.from_json does not work cross-module, use Map.get on the JSON map fields. Parse the event JSON with `Json.parse(event_json)` then `Json.encode()` the result to get a parseable map -- actually, the simpler approach per the research is to construct an EventPayload manually from Map.get fields on the parsed JSON.

**REVISED APPROACH:** Since EventPayload.from_json cannot be called cross-module, and Json.parse returns an opaque Json type (not a Map), use PostgreSQL for the heavy lifting instead. The fingerprint computation needs `message`, `fingerprint` (custom), `stacktrace`, and `exception` fields. Extract these from the JSON string using simple string parsing is fragile.

**BEST APPROACH:** Keep the fingerprint computation in PostgreSQL. Instead of computing the fingerprint in Mesh, pass the raw event JSON to a new SQL function `compute_and_upsert_issue` that:
1. Extracts fields from the JSONB
2. Computes the fingerprint using PostgreSQL string functions
3. Upserts the issue
4. Returns issue_id and fingerprint

Actually, this defeats the purpose of the Mesh fingerprint module. Let me reconsider.

**CORRECT APPROACH:** The EventProcessor already receives the validated `event_json` string. We need field extraction. Since Mesh has Map.get on parsed maps, and Json.parse returns a Json type (not Map), we need a way to get fields. Looking at the existing codebase: the ingestion route handler already has the raw body. We can extract fields using PostgreSQL in a single query that does both fingerprint computation AND issue upsert.

Create a new SQL-based approach in `mesher/storage/queries.mpl`:

`pub fn compute_fingerprint_and_upsert(pool :: PoolHandle, project_id :: String, event_json :: String) -> Map<String, String>!String`

This single query:
1. Extracts fingerprint fields from the JSON
2. Computes the fingerprint with COALESCE fallback chain
3. Checks discard status
4. Upserts the issue
5. Returns `{issue_id, fingerprint, discarded}` as a Map

SQL (using a CTE):
```sql
WITH payload AS (
  SELECT $2::jsonb AS j
),
fp AS (
  SELECT CASE
    WHEN length(COALESCE(j->>'fingerprint', '')) > 0 THEN j->>'fingerprint'
    WHEN j->'stacktrace' IS NOT NULL AND jsonb_array_length(COALESCE(j->'stacktrace', '[]'::jsonb)) > 0 THEN
      (SELECT string_agg(frame->>'filename' || '|' || frame->>'function_name', ';' ORDER BY ordinality)
       FROM jsonb_array_elements(j->'stacktrace') WITH ORDINALITY AS t(frame, ordinality))
      || ':' || lower(COALESCE(replace(j->>'message', '0x', ''), ''))
    WHEN j->'exception' IS NOT NULL AND j->'exception'->>'type_name' IS NOT NULL THEN
      (j->'exception'->>'type_name') || ':' || lower(COALESCE(replace(j->'exception'->>'value', '0x', ''), ''))
    ELSE 'msg:' || lower(COALESCE(replace(j->>'message', '0x', ''), ''))
  END AS fingerprint
  FROM payload
),
upserted AS (
  INSERT INTO issues (project_id, fingerprint, title, level, event_count)
  SELECT $1::uuid, fp.fingerprint,
    COALESCE(NULLIF(j->>'message', ''), 'Untitled'),
    COALESCE(j->>'level', 'error'), 1
  FROM payload, fp
  WHERE NOT EXISTS (
    SELECT 1 FROM issues WHERE project_id = $1::uuid AND fingerprint = fp.fingerprint AND status = 'discarded'
  )
  ON CONFLICT (project_id, fingerprint) DO UPDATE SET
    event_count = issues.event_count + 1,
    last_seen = now(),
    status = CASE WHEN issues.status = 'resolved' THEN 'unresolved' ELSE issues.status END
  RETURNING id::text, status, fingerprint
)
SELECT COALESCE(u.id, 'discarded') AS issue_id,
  fp.fingerprint,
  CASE WHEN u.id IS NULL THEN 'true' ELSE 'false' END AS discarded
FROM fp
LEFT JOIN upserted u ON true
```

Pass params `[project_id, event_json]`. Returns a row with `issue_id`, `fingerprint`, `discarded`.

However, this CTE approach may be too complex for PostgreSQL in one query and might have issues with the NOT EXISTS + ON CONFLICT interaction. Let me simplify.

**SIMPLEST CORRECT APPROACH:**

Keep the Mesh fingerprint module (mesher/ingestion/fingerprint.mpl) as planned in Task 1 but acknowledge it won't be called from EventProcessor directly due to the cross-module from_json limitation. Instead:

1. **In EventProcessor**, do the fingerprint computation in PostgreSQL via a two-step query approach:
   - Step 1: Call `compute_fingerprint_sql(pool, event_json)` which uses a single SELECT to extract and compute the fingerprint from the JSON, returning the fingerprint string.
   - Step 2: Call `upsert_issue(pool, project_id, fingerprint, title, level)` with the computed fingerprint.
   - Step 3: If not discarded, store the event via StorageWriter.

2. **Add to queries.mpl:**
   - `pub fn compute_fingerprint_sql(pool :: PoolHandle, event_json :: String) -> Map<String, String>!String` -- Runs a SELECT that computes fingerprint + extracts title and level from JSON.
   - The existing `upsert_issue` from Task 1 handles the upsert.
   - `is_issue_discarded` from Task 1 handles the discard check.

**Revised implementation for EventProcessor:**

```mesh
from Ingestion.Fingerprint import compute_fingerprint  # Keep for reference/testing
from Storage.Queries import upsert_issue, is_issue_discarded, extract_event_fields
from Services.Writer import StorageWriter

struct ProcessorState do
  pool :: PoolHandle
  processed_count :: Int
end

# Extract event fields from JSON using PostgreSQL jsonb extraction.
# Returns a map with keys: fingerprint, message, level, exception_type, exception_value,
# has_stacktrace, has_custom_fp.
# This avoids cross-module from_json limitations (decision [88-02]).
# The actual function is in Storage.Queries as extract_event_fields.

fn build_enriched_entry(issue_id :: String, fingerprint :: String, event_json :: String) -> String do
  issue_id <> "\t" <> fingerprint <> "\t" <> event_json
end

fn route_event(state :: ProcessorState, project_id :: String, writer_pid, event_json :: String) -> (ProcessorState, String!String) do
  let fields_result = extract_event_fields(state.pool, event_json)
  case fields_result do
    Err(e) ->
      (state, Err(e))
    Ok(fields) ->
      let fingerprint = Map.get(fields, "fingerprint")
      let title = Map.get(fields, "title")
      let level = Map.get(fields, "level")
      process_with_fingerprint(state, project_id, writer_pid, event_json, fingerprint, title, level)
  end
end

fn process_with_fingerprint(state :: ProcessorState, project_id :: String, writer_pid, event_json :: String, fingerprint :: String, title :: String, level :: String) -> (ProcessorState, String!String) do
  let discarded_result = is_issue_discarded(state.pool, project_id, fingerprint)
  case discarded_result do
    Err(e) -> (state, Err(e))
    Ok(discarded) -> process_if_not_discarded(state, project_id, writer_pid, event_json, fingerprint, title, level, discarded)
  end
end

fn process_if_not_discarded(state :: ProcessorState, project_id :: String, writer_pid, event_json :: String, fingerprint :: String, title :: String, level :: String, discarded :: Bool) -> (ProcessorState, String!String) do
  if discarded do
    (state, Ok("discarded"))
  else
    do_upsert_and_store(state, project_id, writer_pid, event_json, fingerprint, title, level)
  end
end

fn do_upsert_and_store(state :: ProcessorState, project_id :: String, writer_pid, event_json :: String, fingerprint :: String, title :: String, level :: String) -> (ProcessorState, String!String) do
  let upsert_result = upsert_issue(state.pool, project_id, fingerprint, title, level)
  case upsert_result do
    Err(e) -> (state, Err(e))
    Ok(issue_id) -> store_enriched_event(state, project_id, writer_pid, event_json, issue_id, fingerprint)
  end
end

fn store_enriched_event(state :: ProcessorState, project_id :: String, writer_pid, event_json :: String, issue_id :: String, fingerprint :: String) -> (ProcessorState, String!String) do
  let enriched = build_enriched_entry(issue_id, fingerprint, event_json)
  StorageWriter.store(writer_pid, enriched)
  let new_state = ProcessorState { pool: state.pool, processed_count: state.processed_count + 1 }
  (new_state, Ok(issue_id))
end
```

Note: Each case arm must be a single expression (decision [88-02]) so multi-step logic is extracted into helper functions.

**Add to queries.mpl:** `extract_event_fields` function:
```mesh
pub fn extract_event_fields(pool :: PoolHandle, event_json :: String) -> Map<String, String>!String do
  let rows = Pool.query(pool, "SELECT CASE WHEN length(COALESCE(j->>'fingerprint', '')) > 0 THEN j->>'fingerprint' WHEN j->'stacktrace' IS NOT NULL AND jsonb_typeof(j->'stacktrace') = 'array' AND jsonb_array_length(j->'stacktrace') > 0 THEN (SELECT string_agg(frame->>'filename' || '|' || frame->>'function_name', ';' ORDER BY ordinality) FROM jsonb_array_elements(j->'stacktrace') WITH ORDINALITY AS t(frame, ordinality)) || ':' || lower(COALESCE(replace(j->>'message', '0x', ''), '')) WHEN j->'exception' IS NOT NULL AND j->'exception'->>'type_name' IS NOT NULL THEN (j->'exception'->>'type_name') || ':' || lower(COALESCE(replace(j->'exception'->>'value', '0x', ''), '')) ELSE 'msg:' || lower(COALESCE(replace(j->>'message', '0x', ''), '')) END AS fingerprint, COALESCE(NULLIF(j->>'message', ''), 'Untitled') AS title, COALESCE(j->>'level', 'error') AS level FROM (SELECT $1::jsonb AS j) AS sub", [event_json])?
  if List.length(rows) > 0 do
    Ok(List.head(rows))
  else
    Err("extract_event_fields: no result")
  end
end
```

This computes the fingerprint in PostgreSQL using the exact same fallback chain as the Mesh fingerprint module (custom > stacktrace frames > exception type > message), including normalize_message (lower + replace 0x). The Mesh fingerprint module in Task 1 remains as documentation/reference but the actual runtime path uses this SQL approach to avoid cross-module from_json limitations.

**Modify `mesher/storage/writer.mpl`** -- Change `insert_event` to accept `issue_id` and `fingerprint` as separate SQL parameters:
```mesh
pub fn insert_event(pool :: PoolHandle, project_id :: String, issue_id :: String, fingerprint :: String, json_str :: String) -> Int!String do
  let result = Pool.execute(pool, "INSERT INTO events (project_id, issue_id, level, message, fingerprint, exception, stacktrace, breadcrumbs, tags, extra, user_context, sdk_name, sdk_version) SELECT $1::uuid, $2::uuid, j->>'level', j->>'message', $3, (j->'exception')::jsonb, (j->'stacktrace')::jsonb, (j->'breadcrumbs')::jsonb, COALESCE((j->'tags')::jsonb, '{}'::jsonb), COALESCE((j->'extra')::jsonb, '{}'::jsonb), (j->'user_context')::jsonb, j->>'sdk_name', j->>'sdk_version' FROM (SELECT $4::jsonb AS j) AS sub", [project_id, issue_id, fingerprint, json_str])
  result
end
```

**Modify `mesher/services/writer.mpl`** -- Update `flush_loop` to parse the tab-delimited enriched entry:
```mesh
fn flush_loop(pool :: PoolHandle, project_id :: String, events, i :: Int, total :: Int) -> Int!String do
  if i < total do
    let entry = List.get(events, i)
    let parts = String.split(entry, "\t")
    let issue_id = List.get(parts, 0)
    let fingerprint = List.get(parts, 1)
    let event_json = List.get(parts, 2)
    insert_event(pool, project_id, issue_id, fingerprint, event_json)?
    flush_loop(pool, project_id, events, i + 1, total)
  else
    Ok(0)
  end
end
```

IMPORTANT: String.split with "\t" -- verify this works in the Mesh runtime. Tab character should be fine as a delimiter since event JSON will not contain raw tabs (JSON escapes them as \t). If String.split doesn't handle "\t", use a different delimiter like "|||" that won't appear in JSON or UUIDs. Test compilation first.

**EventProcessor service block** remains the same structure -- just the `route_event` helper function changes. Keep the service call handler minimal per decision [88-02].
  </action>
  <verify>
1. Run `cd /Users/sn0w/Documents/dev/snow && cargo build --release 2>&1 | tail -30` -- must compile successfully.
2. Verify the enriched flow compiles: EventProcessor imports from Ingestion.Fingerprint, Storage.Queries, and Services.Writer. Check for type inference errors.
3. Check the SQL in extract_event_fields is valid by visual inspection of the CASE expression and string_agg subquery.
  </verify>
  <done>
EventProcessor enriches events with fingerprint computation and issue upsert before storage. insert_event accepts issue_id and fingerprint as separate parameters. StorageWriter parses enriched entries to extract issue_id and fingerprint. Full event grouping pipeline is wired: event -> extract fields (SQL) -> check discard -> upsert issue (with regression detection) -> store enriched event. Requirements GROUP-01 through GROUP-05 and ISSUE-02 satisfied.
  </done>
</task>

</tasks>

<verification>
1. Compile: `cd /Users/sn0w/Documents/dev/snow && cargo build --release` must succeed with zero errors.
2. Code review: EventProcessor.route_event calls extract_event_fields -> is_issue_discarded -> upsert_issue -> StorageWriter.store.
3. SQL review: upsert_issue uses ON CONFLICT with regression detection CASE. extract_event_fields implements full fallback chain.
4. File structure: mesher/ingestion/fingerprint.mpl exists with compute_fingerprint. Storage queries extended with 3 new functions.
</verification>

<success_criteria>
- mesher/ingestion/fingerprint.mpl exists with compute_fingerprint implementing custom > stacktrace > exception > message fallback
- queries.mpl has extract_event_fields (SQL-based fingerprint computation), upsert_issue (ON CONFLICT with regression), is_issue_discarded
- storage/writer.mpl insert_event accepts issue_id and fingerprint as separate params
- services/writer.mpl flush_loop splits enriched entries to extract issue_id and fingerprint
- services/event_processor.mpl enriches events: extract fields -> check discard -> upsert issue -> store
- Project compiles with `cargo build --release`
</success_criteria>

<output>
After completion, create `.planning/phases/89-error-grouping-issue-lifecycle/89-01-SUMMARY.md`
</output>
