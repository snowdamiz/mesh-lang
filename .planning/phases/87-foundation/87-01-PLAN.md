---
phase: 87-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mesher/types/event.mpl
  - mesher/types/issue.mpl
  - mesher/types/project.mpl
  - mesher/types/user.mpl
  - mesher/types/alert.mpl
  - mesher/storage/schema.mpl
  - mesher/storage/queries.mpl
autonomous: true
user_setup:
  - service: postgresql
    why: "Database storage for all Mesher data"
    env_vars:
      - name: DATABASE_URL
        source: "Local PostgreSQL 18+ installation (e.g., postgres://mesh:mesh@localhost:5432/mesher)"
    dashboard_config:
      - task: "Create database 'mesher' and enable pgcrypto extension"
        location: "psql or any PostgreSQL client"

must_haves:
  truths:
    - "All core data types compile with deriving(Json, Row) annotations"
    - "PostgreSQL schema creates all 10 tables with correct constraints and indexes"
    - "Events table is partitioned by range on received_at with daily partitions"
    - "All entity IDs use UUIDv7 via PostgreSQL DEFAULT uuidv7()"
    - "Query helper functions provide reusable SQL operations for all entity types"
  artifacts:
    - path: "mesher/types/event.mpl"
      provides: "Event, Severity, StackFrame, ExceptionInfo, Breadcrumb structs"
      contains: "deriving(Json)"
    - path: "mesher/types/issue.mpl"
      provides: "Issue, IssueStatus structs"
      contains: "deriving(Json, Row)"
    - path: "mesher/types/project.mpl"
      provides: "Organization, Project, ApiKey structs"
      contains: "deriving(Json, Row)"
    - path: "mesher/types/user.mpl"
      provides: "User, OrgMembership, Session structs"
      contains: "deriving(Json, Row)"
    - path: "mesher/types/alert.mpl"
      provides: "AlertRule, AlertCondition structs"
      contains: "deriving(Json, Row)"
    - path: "mesher/storage/schema.mpl"
      provides: "create_schema function with all DDL"
      contains: "PARTITION BY RANGE"
    - path: "mesher/storage/queries.mpl"
      provides: "Reusable query functions for CRUD operations"
      contains: "Pool.query"
  key_links:
    - from: "mesher/storage/schema.mpl"
      to: "PostgreSQL"
      via: "Pool.execute for DDL"
      pattern: "Pool\\.execute.*CREATE TABLE"
    - from: "mesher/storage/queries.mpl"
      to: "PostgreSQL"
      via: "Pool.query_as with from_row"
      pattern: "Pool\\.query_as"
    - from: "mesher/types/*.mpl"
      to: "mesher/storage/queries.mpl"
      via: "Row structs used as query return types"
      pattern: "from_row"
---

<objective>
Define all Mesher data types and create the PostgreSQL persistence layer.

Purpose: Establish the complete data model and database schema that all subsequent phases depend on. Every struct, every table, every index -- defined once, used everywhere.
Output: 7 Mesh source files defining all types, the full DDL schema, and reusable query helper functions.
</objective>

<execution_context>
@/Users/sn0w/.claude/get-shit-done/workflows/execute-plan.md
@/Users/sn0w/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/87-foundation/87-CONTEXT.md
@.planning/phases/87-foundation/87-RESEARCH.md

# Reference patterns from existing Mesh test files
@tests/e2e/deriving_json_basic.mpl
@tests/e2e/deriving_row_basic.mpl
@tests/e2e/stdlib_pg.mpl
@tests/e2e/service_counter.mpl
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define all Mesher data type structs</name>
  <files>
    mesher/types/event.mpl
    mesher/types/issue.mpl
    mesher/types/project.mpl
    mesher/types/user.mpl
    mesher/types/alert.mpl
  </files>
  <action>
Create the `mesher/` project directory with `mesher/types/` subdirectory. Create all 5 type definition files.

**mesher/types/event.mpl** -- Module `Types.Event`:
- `type Severity do Fatal | Error | Warning | Info | Debug end deriving(Json)` -- 5 levels per Sentry convention (LOCKED decision)
- `struct StackFrame do filename :: String, function_name :: String, lineno :: Int, colno :: Int, context_line :: String, in_app :: Bool end deriving(Json)` -- structured frames for fingerprinting and display (discretion: structured JSONB, not raw strings)
- `struct ExceptionInfo do type_name :: String, value :: String, module :: String end deriving(Json)` -- exception metadata
- `struct Breadcrumb do timestamp :: String, category :: String, message :: String, level :: String, data :: String end deriving(Json)` -- data field is JSON string for flexible JSONB
- `struct Event do id :: String, project_id :: String, issue_id :: String, level :: String, message :: String, fingerprint :: String, exception :: String, stacktrace :: String, breadcrumbs :: String, tags :: String, extra :: String, user_context :: String, sdk_name :: String, sdk_version :: String, received_at :: String end deriving(Json, Row)` -- ALL String fields because deriving(Row) maps through Map<String, String> text protocol. JSONB columns (exception, stacktrace, breadcrumbs, tags, extra, user_context) arrive as JSON strings that must be parsed with from_json() in a separate step. This is the Row struct for database reads.
- `struct EventPayload do message :: String, level :: String, fingerprint :: String, exception :: Option<ExceptionInfo>, stacktrace :: Option<List<StackFrame>>, breadcrumbs :: Option<List<Breadcrumb>>, tags :: String, extra :: String, user_context :: String, sdk_name :: Option<String>, sdk_version :: Option<String> end deriving(Json)` -- typed payload struct for JSON deserialization of incoming events (not a Row struct)

Note on tags: stored as `Map<String, String>` conceptually but typed as String in Row structs since JSONB arrives as text via the PG text protocol.

Make all struct fields `pub` by using `pub` on the struct. Use `pub struct` and `pub type` for all exported types. Use `pub fn` for any helper functions.

**mesher/types/issue.mpl** -- Module `Types.Issue`:
- `type IssueStatus do Unresolved | Resolved | Archived end deriving(Json)` -- state machine for issues
- `struct Issue do id :: String, project_id :: String, fingerprint :: String, title :: String, level :: String, status :: String, event_count :: Int, first_seen :: String, last_seen :: String, assigned_to :: Option<String> end deriving(Json, Row)` -- status stored as text in DB, parsed to IssueStatus via from_json when needed

**mesher/types/project.mpl** -- Module `Types.Project`:
- `struct Organization do id :: String, name :: String, slug :: String, created_at :: String end deriving(Json, Row)`
- `struct Project do id :: String, org_id :: String, name :: String, platform :: Option<String>, created_at :: String end deriving(Json, Row)`
- `struct ApiKey do id :: String, project_id :: String, key_value :: String, label :: String, created_at :: String, revoked_at :: Option<String> end deriving(Json, Row)` -- multiple keys per project (LOCKED decision), mshr_ prefix format (LOCKED decision)

**mesher/types/user.mpl** -- Module `Types.User`:
- `struct User do id :: String, email :: String, display_name :: String, created_at :: String end deriving(Json, Row)` -- NO password_hash field in the struct (never expose to application code)
- `struct OrgMembership do id :: String, user_id :: String, org_id :: String, role :: String, joined_at :: String end deriving(Json, Row)` -- role is owner/admin/member
- `struct Session do token :: String, user_id :: String, created_at :: String, expires_at :: String end deriving(Json, Row)`

**mesher/types/alert.mpl** -- Module `Types.Alert`:
- `struct AlertRule do id :: String, project_id :: String, name :: String, condition_json :: String, action_json :: String, enabled :: Bool, created_at :: String end deriving(Json, Row)` -- condition_json and action_json are JSONB stored as String in Row struct
- `struct AlertCondition do condition_type :: String, threshold :: Int, window_minutes :: Int end deriving(Json)` -- typed condition for JSON parsing

Each file must start with `module Types.X` declaration matching the file path convention (types/event.mpl -> Types.Event).
  </action>
  <verify>
Run `ls -la mesher/types/` to confirm all 5 files exist. Verify each file has the correct module declaration, struct definitions, and deriving annotations by reading them. Count that all structs are present: Event, EventPayload, Severity, StackFrame, ExceptionInfo, Breadcrumb, Issue, IssueStatus, Organization, Project, ApiKey, User, OrgMembership, Session, AlertRule, AlertCondition (16 types total).
  </verify>
  <done>All 5 type files exist with 16 total struct/sum type definitions, all with appropriate deriving(Json) and/or deriving(Json, Row) annotations. Row structs use String fields for all database columns. Sum types (Severity, IssueStatus) use deriving(Json) only.</done>
</task>

<task type="auto">
  <name>Task 2: Create PostgreSQL schema DDL and query helpers</name>
  <files>
    mesher/storage/schema.mpl
    mesher/storage/queries.mpl
  </files>
  <action>
Create `mesher/storage/` subdirectory. Create both storage foundation files.

**mesher/storage/schema.mpl** -- Module `Storage.Schema`:

Create a `pub fn create_schema(pool :: Int) -> Int!String` function that executes all DDL via `Pool.execute`. The function must:

1. Enable pgcrypto extension: `CREATE EXTENSION IF NOT EXISTS pgcrypto`
2. Create all 10 tables in dependency order (foreign keys require parent tables first):
   - organizations (id UUID PK DEFAULT uuidv7(), name TEXT NOT NULL, slug TEXT UNIQUE NOT NULL, created_at TIMESTAMPTZ DEFAULT now())
   - users (id UUID PK DEFAULT uuidv7(), email TEXT UNIQUE NOT NULL, password_hash TEXT NOT NULL, display_name TEXT NOT NULL, created_at TIMESTAMPTZ DEFAULT now())
   - org_memberships (id UUID PK DEFAULT uuidv7(), user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE, org_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE, role TEXT NOT NULL DEFAULT 'member', joined_at TIMESTAMPTZ DEFAULT now(), UNIQUE(user_id, org_id))
   - sessions (token TEXT PK, user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE, created_at TIMESTAMPTZ DEFAULT now(), expires_at TIMESTAMPTZ DEFAULT now() + interval '7 days')
   - projects (id UUID PK DEFAULT uuidv7(), org_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE, name TEXT NOT NULL, platform TEXT, created_at TIMESTAMPTZ DEFAULT now())
   - api_keys (id UUID PK DEFAULT uuidv7(), project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE, key_value TEXT UNIQUE NOT NULL, label TEXT NOT NULL DEFAULT 'default', created_at TIMESTAMPTZ DEFAULT now(), revoked_at TIMESTAMPTZ)
   - issues (id UUID PK DEFAULT uuidv7(), project_id UUID NOT NULL, fingerprint TEXT NOT NULL, title TEXT NOT NULL, level TEXT NOT NULL, status TEXT NOT NULL DEFAULT 'unresolved', event_count INTEGER NOT NULL DEFAULT 0, first_seen TIMESTAMPTZ DEFAULT now(), last_seen TIMESTAMPTZ DEFAULT now(), assigned_to UUID REFERENCES users(id), UNIQUE(project_id, fingerprint))
   - events PARTITION BY RANGE (received_at) -- composite PK (id, received_at) because PostgreSQL requires partition key in PK (LOCKED decision for daily partitioning)
   - alert_rules (id UUID PK DEFAULT uuidv7(), project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE, name TEXT NOT NULL, condition_json JSONB NOT NULL, action_json JSONB NOT NULL, enabled BOOLEAN NOT NULL DEFAULT true, created_at TIMESTAMPTZ DEFAULT now())

3. Create all indexes (use CREATE INDEX IF NOT EXISTS):
   - idx_org_memberships_user ON org_memberships(user_id)
   - idx_org_memberships_org ON org_memberships(org_id)
   - idx_sessions_user ON sessions(user_id)
   - idx_sessions_expires ON sessions(expires_at)
   - idx_projects_org ON projects(org_id)
   - idx_api_keys_project ON api_keys(project_id)
   - idx_api_keys_value ON api_keys(key_value) WHERE revoked_at IS NULL
   - idx_issues_project_status ON issues(project_id, status)
   - idx_issues_project_last_seen ON issues(project_id, last_seen DESC)
   - idx_events_project_received ON events(project_id, received_at DESC)
   - idx_events_issue_received ON events(issue_id, received_at DESC)
   - idx_events_level ON events(level, received_at DESC)
   - idx_events_fingerprint ON events(fingerprint)
   - idx_events_tags ON events USING GIN(tags jsonb_path_ops)
   - idx_alert_rules_project ON alert_rules(project_id) WHERE enabled = true

Use `CREATE TABLE IF NOT EXISTS` and `CREATE INDEX IF NOT EXISTS` for idempotency. Chain all Pool.execute calls with `?` for error propagation. Return `Ok(0)` on success.

Create a `pub fn create_partition(pool :: Int, date_str :: String) -> Int!String` function that creates a single daily partition for the events table. The partition name format is `events_YYYYMMDD`. SQL: `CREATE TABLE IF NOT EXISTS events_{date_str} PARTITION OF events FOR VALUES FROM ('{formatted_date}') TO ('{next_day}')`. The date_str parameter is in YYYYMMDD format (e.g., "20260214"). You need to format it to YYYY-MM-DD for the partition bounds. Use string concatenation to build the SQL.

Create a `pub fn create_partitions_ahead(pool :: Int, days :: Int) -> Int!String` function that queries PostgreSQL for the current date via `SELECT to_char(now() + (n || ' days')::interval, 'YYYYMMDD')` for each day offset 0..days, then calls `create_partition` for each. Since Mesh has no current date/time function, ALL date computation happens in PostgreSQL. Use a loop: `let i = 0` then `while i < days` pattern. For each iteration, query `SELECT to_char(now() + ($1 || ' days')::interval, 'YYYYMMDD') AS d` passing `String.from_int(i)` as $1, extract the date string from the result, and call create_partition.

Note: Use `Pool.query` (not Pg.query) since schema operations should go through the pool for connection management. All Pool functions take the pool handle (Int) as first argument.

**mesher/storage/queries.mpl** -- Module `Storage.Queries`:

Create reusable query helper functions. Import types from Types.Project, Types.User, Types.Issue, Types.Event, Types.Alert modules.

Organization queries:
- `pub fn insert_org(pool :: Int, name :: String, slug :: String) -> String!String` -- INSERT RETURNING id, use Pool.query for RETURNING
- `pub fn get_org(pool :: Int, id :: String) -> Organization!String` -- SELECT by id, use Pool.query_as with Organization.from_row
- `pub fn list_orgs(pool :: Int) -> List<Organization>!String` -- SELECT all

Project queries:
- `pub fn insert_project(pool :: Int, org_id :: String, name :: String, platform :: String) -> String!String` -- INSERT RETURNING id
- `pub fn get_project(pool :: Int, id :: String) -> Project!String` -- SELECT by id
- `pub fn list_projects_by_org(pool :: Int, org_id :: String) -> List<Project>!String` -- SELECT WHERE org_id

API key queries:
- `pub fn create_api_key(pool :: Int, project_id :: String, label :: String) -> String!String` -- INSERT with `'mshr_' || encode(gen_random_bytes(24), 'hex')` for key_value (LOCKED: mshr_ prefix), RETURNING key_value
- `pub fn get_project_by_api_key(pool :: Int, key_value :: String) -> Project!String` -- JOIN api_keys ON projects WHERE key_value = $1 AND revoked_at IS NULL
- `pub fn revoke_api_key(pool :: Int, key_id :: String) -> Int!String` -- UPDATE SET revoked_at = now()

User queries:
- `pub fn create_user(pool :: Int, email :: String, password :: String, display_name :: String) -> String!String` -- INSERT with `crypt($2, gen_salt('bf', 12))` for password hashing (bcrypt cost 12 via pgcrypto), RETURNING id
- `pub fn authenticate_user(pool :: Int, email :: String, password :: String) -> User!String` -- SELECT WHERE email = $1 AND password_hash = crypt($2, password_hash)
- `pub fn get_user(pool :: Int, id :: String) -> User!String`

Session queries:
- `pub fn create_session(pool :: Int, user_id :: String) -> String!String` -- INSERT with `encode(gen_random_bytes(32), 'hex')` for token, RETURNING token (opaque 64-char hex, not JWT -- discretion choice)
- `pub fn validate_session(pool :: Int, token :: String) -> Session!String` -- SELECT WHERE token = $1 AND expires_at > now()
- `pub fn delete_session(pool :: Int, token :: String) -> Int!String` -- DELETE WHERE token

Org membership queries:
- `pub fn add_member(pool :: Int, user_id :: String, org_id :: String, role :: String) -> String!String` -- INSERT RETURNING id
- `pub fn get_members(pool :: Int, org_id :: String) -> List<OrgMembership>!String`
- `pub fn get_user_orgs(pool :: Int, user_id :: String) -> List<OrgMembership>!String`

For all query functions that return a single entity (get_org, get_project, etc.), handle the empty result case: if Pool.query_as returns an empty list, return `Err("not found")`. Use `case results do [item] -> Ok(item) | _ -> Err("not found") end` pattern.

For insert functions that use RETURNING, use `Pool.query` (returns List<Map<String, String>>) and extract the value with `Map.get(row, "column_name")`.

Import all needed type modules at the top of the file with `from Types.Project import { Organization, Project, ApiKey }` etc.
  </action>
  <verify>
Run `ls -la mesher/storage/` to confirm both files exist. Read both files and verify: schema.mpl has create_schema with all 10 CREATE TABLE statements and 15 CREATE INDEX statements, plus create_partition and create_partitions_ahead functions. queries.mpl has all query helper functions (at least 17 pub fn declarations) with proper imports from Types modules.
  </verify>
  <done>schema.mpl creates the complete PostgreSQL schema (10 tables, 15 indexes, daily event partitioning) idempotently via Pool.execute. queries.mpl provides reusable CRUD functions for all entity types with proper error handling, bcrypt password hashing via pgcrypto, and cryptographic API key/session token generation via PostgreSQL.</done>
</task>

</tasks>

<verification>
1. All 7 files exist under mesher/ with correct directory structure (types/ and storage/ subdirectories)
2. Each file has a `module X.Y` declaration matching its path (e.g., types/event.mpl -> module Types.Event)
3. All 16 type definitions present with correct deriving annotations
4. Schema DDL includes all 10 tables with correct foreign key relationships
5. Events table uses PARTITION BY RANGE with composite PK (id, received_at)
6. All UUIDs default to uuidv7()
7. Query helpers cover all CRUD operations for all entity types
</verification>

<success_criteria>
- 7 .mpl files exist in mesher/types/ and mesher/storage/
- All data types compile-ready with deriving(Json) and/or deriving(Row)
- Full PostgreSQL DDL schema with partitioning, indexes, and pgcrypto
- Reusable query functions for every entity type
- mshr_ API key format implemented in SQL (LOCKED decision)
- bcrypt password hashing via pgcrypto (LOCKED decision)
- Opaque session tokens via gen_random_bytes (discretion choice)
</success_criteria>

<output>
After completion, create `.planning/phases/87-foundation/87-01-SUMMARY.md`
</output>
